{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_2 = labelDf.loc[[int(star) for star in train_stars]]\n",
    "m_star = train_labels_2.mean(axis=1)\n",
    "s_star = train_labels_2.std(axis=1)\n",
    "# normalize all stars such that they have a similar spectrum\n",
    "for col in train_labels_2.columns:\n",
    "    train_labels_2[col] = (train_labels_2[col] - m_star)/s_star\n",
    "\n",
    "m_wl = train_labels_2.mean(axis=0)\n",
    "s_wl = train_labels_2.std(axis=0)\n",
    "\n",
    "#normalize every wavelengths such that it has values between -1,1\n",
    "for col in train_labels_2.columns:\n",
    "    train_labels_2[col] = (train_labels_2[col] - m_wl[col])/s_wl[col]\n",
    "\n",
    "train_labels_2['s'] = abs(train_labels_2).sum(axis=1)\n",
    "train_labels_2.s.std(), train_labels_2.s.mean(), train_labels_2.s.max(), train_labels_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    labelDf = pd.read_csv(\"train_labels.csv\")\n",
    "    labelDf = labelDf.set_index('planet_id')\n",
    "    meanLabels = np.mean(labelDf.mean())\n",
    "    stdLabels = np.std(labelDf.std())\n",
    "    maxLabels = np.max(labelDf.max())\n",
    "    minLabels = np.min(labelDf.min())\n",
    "\n",
    "    trainLabels = labelDf.loc[[int(star) for star in train_stars]].copy()\n",
    "    meanTrainLabels = np.mean(trainLabels.mean())\n",
    "    stdTrainLabels = np.std(trainLabels.std())\n",
    "    maxTrainLabels = np.max(trainLabels.max())\n",
    "    minTrainLabels = np.min(trainLabels.min())\n",
    "\n",
    "    #scale up data\n",
    "    for col in labelDf.columns:\n",
    "        labelDf.loc[:,col] = (labelDf[col]) / (maxTrainLabels)\n",
    "\n",
    "    m_star = labelDf.mean(axis=1)\n",
    "    s_star = labelDf.std(axis=1)\n",
    "    # normalize all stars such that they have a similar spectrum -> we need to predict those values as well\n",
    "    for col in trainLabels.columns:\n",
    "        #trainLabels[col] = (trainLabels[col] - m_star)/s_star\n",
    "        labelDf[col] = (labelDf[col] - m_star)/s_star\n",
    "\n",
    "    trainLabels = labelDf.loc[[int(star) for star in train_stars]]\n",
    "    m_wl = trainLabels.mean(axis=0)\n",
    "    s_wl = trainLabels.std(axis=0)\n",
    "\n",
    "    #normalize every wavelengths such that it has values between -1,1 -> those are constants per wavelength\n",
    "    for col in labelDf.columns:\n",
    "        labelDf[col] = (labelDf[col] - m_wl[col])/s_wl[col]\n",
    "    labelDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in [0,1,2,3]:\n",
    "    fig.add_trace(go.Scatter(y=train_labels_2.iloc[i],mode='markers',marker=dict(size=3)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stars_1, test_stars_1\n",
    "import pickle\n",
    "with open('train_stars_1.pkl', 'wb') as file:\n",
    "    pickle.dump(train_stars_1, file)\n",
    "\n",
    "with open('test_stars_1.pkl', 'wb') as file:\n",
    "    pickle.dump(test_stars_1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_stars), len(test_stars),list(set(test_stars) &set(train_stars_1)) # overlap of old training & new validation -> no old training in valiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "files = glob.glob(os.path.join('train/', '*/*'))\n",
    "stars = []\n",
    "for file in files:\n",
    "    file_name = file.split('\\\\')[1]\n",
    "    stars.append(file_name)\n",
    "stars = np.unique(stars)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def split_star_list(file_list, test_ratio=0.1):\n",
    "    random.shuffle(file_list)\n",
    "    split_index = int(len(file_list) * (1 - test_ratio))\n",
    "    train_files = file_list[:split_index]\n",
    "    test_files = file_list[split_index:]\n",
    "    return train_files, test_files\n",
    "\n",
    "train_stars, test_stars = split_star_list(stars)\n",
    "\n",
    "labelDf = pd.read_csv(\"train_labels.csv\")\n",
    "labelDf = labelDf.set_index('planet_id')\n",
    "meanLabels = np.mean(labelDf.mean())\n",
    "stdLabels = np.std(labelDf.std())\n",
    "maxLabels = np.max(labelDf.max())\n",
    "minLabels = np.min(labelDf.min())\n",
    "\n",
    "trainLabels = labelDf.loc[[int(star) for star in train_stars]]\n",
    "meanTrainLabels = np.mean(trainLabels.mean())\n",
    "stdTrainLabels = np.std(trainLabels.std())\n",
    "maxTrainLabels = np.max(trainLabels.max())\n",
    "minTrainLabels = np.min(trainLabels.min())\n",
    "\n",
    "for col in labelDf.columns:\n",
    "    labelDf.loc[:,col] = (labelDf[col]) / (maxTrainLabels)\n",
    "\n",
    "# normalize over time and all samples, so we have a mean and a std dev per wavelength for all samples\n",
    "def calcMeanAndStdOfTrain(train_stars):\n",
    "    i = 0\n",
    "    for star in train_stars:\n",
    "        file_path = 'train/'+str(star)+'/combined.npz'\n",
    "        with np.load(file_path) as data:\n",
    "            x = data['a'][0,:,0:283,:]\n",
    "            if i ==0:\n",
    "                mean = np.mean(x,axis=(0))\n",
    "                sumS = np.sum(x**2,axis=0)\n",
    "            else:\n",
    "                mean = mean + np.mean(x, axis=(0))\n",
    "                sumS += np.sum(x**2,axis=0)\n",
    "            i=i+1\n",
    "    meanTrain = mean / i\n",
    "    stdTrain = np.sqrt(sumS / (i*x.shape[0]) - meanTrain**2)    \n",
    "    return meanTrain, stdTrain\n",
    "meanTrain, stdTrain = calcMeanAndStdOfTrain(train_stars)\n",
    "\n",
    "def normalize_over_train(features, labels):\n",
    "    #features = (features - meanTrain) / (stdTrain + 1e-6)\n",
    "    features = (features - meanTrain) / (stdTrain + 1e-6)\n",
    "    return features, labels\n",
    "\n",
    "# normalize over time per samples, so we have a mean and a std dev per wavelength for all samples\n",
    "def calcMeanAndStdOfTrainPerStar(x):\n",
    "    mean = np.mean(x,axis=(0))\n",
    "    sumS = np.sum(x**2,axis=0)\n",
    "    stdTrain = np.sqrt(sumS / (x.shape[0]) - mean**2)    \n",
    "    return mean, stdTrain\n",
    "def normalize_per_sample(features, labels):\n",
    "    m,s = calcMeanAndStdOfTrainPerStar(features)\n",
    "    features = (features) / (s + 1e-6)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_npz(star):\n",
    "    integer_value = tf.strings.to_number(star, out_type=tf.int64)\n",
    "    python_int = integer_value.numpy()\n",
    "\n",
    "    file_path = 'train/'+str(python_int)+'/combined.npz'\n",
    "    try:\n",
    "        with np.load(file_path) as data:\n",
    "            features = data['a'][0,:,0:283,:]\n",
    "            labels = labelDf.loc[python_int].to_numpy()\n",
    "            meanL = np.mean(labels)\n",
    "            stdL = np.std(labels)\n",
    "            labels = (labels-meanL)*100 / stdL\n",
    "            features = np.reshape(features,(-1,25,283,4))\n",
    "            features = np.mean(features,axis=1)\n",
    "            #features, labels = normalize_per_sample(features,labels)\n",
    "            features, labels = normalize_over_train(features,labels)\n",
    "            return features, labels\n",
    "    except Exception as e:\n",
    "        print(\"Error loading file:\", e, python_int)\n",
    "\n",
    "\n",
    "def create_dataset(star_list, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(star_list)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(star_list), reshuffle_each_iteration=True)\n",
    "    def load_and_process(x):\n",
    "        features, labels = tf.py_function(\n",
    "            func=load_npz,\n",
    "            inp=[x],\n",
    "            Tout=[tf.float64, tf.float32]\n",
    "        )\n",
    "        return features, labels\n",
    "\n",
    "    dataset = dataset.map(load_and_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(lambda x, y: (tf.ensure_shape(x,tf.TensorShape([225, 283, 4])), tf.ensure_shape(y, tf.TensorShape(283)))) #5625\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = create_dataset(train_stars, batch_size, shuffle=True)\n",
    "test_dataset = create_dataset(test_stars, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = create_dataset(train_stars[0:batch_size], batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_dataset:\n",
    "    print(y[0,0])\n",
    "for x,y in test_dataset:\n",
    "    print('test',y[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape1(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0,2,1,3])\n",
    "        #x = tf.reshape(x, [-1, self.timepoints, tf.cast(self.wavelengths * self.representations, tf.int32)])\n",
    "        return x\n",
    "    \n",
    "class Reshape11(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0,2,1])\n",
    "        #x = tf.reshape(x, [-1, self.timepoints, tf.cast(self.wavelengths * self.representations, tf.int32)])\n",
    "        return x\n",
    "\n",
    "class Reshape2(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x_pred, x_confidence):\n",
    "        x = tf.concat([x_pred, x_confidence], axis = -1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Reshape22(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x_pred, x_confidence):\n",
    "        x_pred = tf.expand_dims(x_pred, axis=-1)\n",
    "        x_confidence = tf.expand_dims(x_confidence, axis=-1)\n",
    "        x = tf.concat([x_pred, x_confidence], axis = -1)\n",
    "        return x\n",
    "    \n",
    "class Reshape3(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, (None,-1,x.shape[2]))\n",
    "        return x\n",
    "    \n",
    "class reduce(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        mean = tf.reduce_sum(x,axis=-1)\n",
    "        mean = tf.expand_dims(mean, axis=-1)\n",
    "        return mean\n",
    "class reduce1(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        mean = tf.reduce_sum(x,axis=-1)\n",
    "        return mean\n",
    "    \n",
    "class tile(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x,mean):\n",
    "        x = tf.concat([x,mean],axis=-1)\n",
    "        return x\n",
    "    \n",
    "class tile2(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x,mean):\n",
    "        x = tf.concat([x,tf.expand_dims(mean,axis=-1)],axis=-2)\n",
    "        return x\n",
    "    \n",
    "class meanOfWavelengths(tf.keras.layers.Layer):\n",
    "    def __init__(self, concat=True,**kwargs):\n",
    "        self.concat=concat\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        m = tf.expand_dims(tf.reduce_mean(x,axis=-1),axis=-1)\n",
    "        x = tf.concat([x,m],axis=-1)\n",
    "        return x if self.concat else m\n",
    "\n",
    "# gated linear unit, splits input in 2 batches, second batch is activation\n",
    "class GLU(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x, mask=None):\n",
    "        x,gate = tf.split(x, 2, axis = -1)\n",
    "        # swish = gate * sigmoid(gate) (sigmoid = between 0..1)\n",
    "        x = x*tf.keras.activations.swish(gate) # use one input as a gate such that the network is able to focus on information\n",
    "        return x\n",
    "\n",
    "class GLUMlp(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim_expand, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim_expand = dim_expand\n",
    "        self.dim = dim\n",
    "        # same operation as dense layer\n",
    "        self.dense_1 = tf.keras.layers.EinsumDense(\"abc,cd->abd\",output_shape=(None, self.dim_expand), activation = 'linear', bias_axes = 'd')\n",
    "        self.glu_1 = GLU()\n",
    "        self.dense_2 = tf.keras.layers.EinsumDense(\"abc,cd->abd\",output_shape=(None, self.dim), activation = 'linear', bias_axes = 'd')\n",
    "    def call(self, x, training = False):\n",
    "        #print('glu_input',x.shape)\n",
    "        x = self.dense_1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.glu_1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.dense_2(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "class ScaleBias(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.scale_bias = tf.keras.layers.EinsumDense(\"abc,c->abc\",output_shape=(None, input_shape[-1]),activation = 'linear', bias_axes = 'c')\n",
    "    def call(self, x, mask=None):\n",
    "        return self.scale_bias(x)\n",
    "\n",
    "#attention gets calculated along first dimension!\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim):\n",
    "        super().__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim//num_heads)\n",
    "        self.ffn = GLUMlp(feed_forward_dim, embed_dim)\n",
    "        #self.ffn = tf.keras.layers.Dense(feed_forward_dim)\n",
    "        self.layer_norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6) # normalization by a * (input-mean) /sqrt(var + eps) +b    where a and b are learned, eps is to avoid div/0\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        #self.scale_bias_1 = ScaleBias()\n",
    "        #self.scale_bias_2 = ScaleBias()\n",
    "    def call(self, x, training = None):\n",
    "        residual = x\n",
    "        #print('before att')\n",
    "        x = self.att(x, x)\n",
    "        #x = self.scale_bias_1(x)\n",
    "        x = self.layer_norm_1(x + residual)\n",
    "        #x = x+residual\n",
    "        residual = x\n",
    "        #print('after att')\n",
    "        x = self.ffn(x, training = training)\n",
    "        #print('after glu')\n",
    "        #x = self.scale_bias_2(x)\n",
    "        x = self.layer_norm_2(x + residual)\n",
    "        return x\n",
    "    \n",
    "# is effectively an attention mechanism to allow some columns to be used / turned off\n",
    "# effective channel attention!\n",
    "class ECA(tf.keras.layers.Layer):\n",
    "    # TF implementation from https://www.kaggle.com/code/hoyso48/1st-place-solution-training\n",
    "    def __init__(self, kernel_size=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False) # only one1D convolution with kernel size\n",
    "    def call(self, inputs):\n",
    "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs) # works not on batch size, but on next dimension, e.g. batch_size, 60x9 -> works on 60, so output is batch_size x 9\n",
    "        nn = tf.expand_dims(nn, -1) # a,c -> a,c,1\n",
    "        nn = self.conv(nn) # a,c,1 -> a,c,1 (1, because conv is only having 1 filter)\n",
    "        nn = tf.squeeze(nn, -1) # a,c,1 -> a,c\n",
    "        nn = tf.nn.sigmoid(nn) # a,c -> a,c\n",
    "        nn = nn[:,None,:] # a,1,c -> e.g. batch_size,1,9\n",
    "        return inputs * nn # a,1,c * a,b,c applies broadcasting / elementwise multiplication -> turns input on or off column wise\n",
    "\n",
    "\n",
    "class HeadDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, head_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.head_dim = head_dim\n",
    "    def build(self, input_shape):\n",
    "        self.length = input_shape[1]\n",
    "        self.dim = input_shape[2]\n",
    "        self.dense = tf.keras.layers.EinsumDense(\"abc,cd->abd\",output_shape=(self.length, self.head_dim), activation = 'swish', bias_axes = 'd') #siwsh is causing a self gating\n",
    "    def call(self, x):\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "class Conv1DBlockSqueezeformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, channel_size, kernel_size, dilation_rate=1,\n",
    "                 expand_ratio=2, se_ratio=0.25, activation='swish', name=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.channel_size = channel_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.se_ratio = se_ratio\n",
    "        self.activation = activation\n",
    "        self.scale_bias = ScaleBias()\n",
    "        self.glu_layer = GLU()\n",
    "        self.ffn = GLUMlp(channel_size*4, channel_size)\n",
    "        self.layer_norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.scale_bias_1 = ScaleBias()\n",
    "        self.scale_bias_2 = ScaleBias()\n",
    "    def build(self, input_shape):\n",
    "        self.length = input_shape[1]\n",
    "        self.channels_in = input_shape[2]\n",
    "        self.channels_expand = self.channels_in * self.expand_ratio\n",
    "        self.dwconv = tf.keras.layers.DepthwiseConv1D(self.kernel_size,dilation_rate=self.dilation_rate,padding='same',use_bias=False)\n",
    "        self.BatchNormalization_layer = tf.keras.layers.BatchNormalization(momentum=0.95)\n",
    "        self.conv_activation = tf.keras.layers.Activation(self.activation)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ECA_layer = ECA() #convolutional attention\n",
    "        self.expand = tf.keras.layers.EinsumDense(\"abc,cd->abd\",output_shape=(self.length, self.channels_expand), activation = 'linear', bias_axes = 'd')\n",
    "        self.project =tf.keras.layers.EinsumDense(\"abc,cd->abd\",output_shape=(self.length, self.channel_size), activation = 'linear', bias_axes = 'd')\n",
    "    def call(self, x, training = None):\n",
    "        skip = x\n",
    "        #print(x.shape)\n",
    "        x = self.expand(x) #dense layer expands time dimension\n",
    "        #print(x.shape)\n",
    "        x = self.glu_layer(x) # gating of input through linear gating unit, 2 halfs, second half = activation of first(=input)\n",
    "        #print('glu',x.shape)\n",
    "        x = self.dwconv(x)\n",
    "        #print('conv filter',x.shape)\n",
    "        x = self.BatchNormalization_layer(x)\n",
    "        #print('batchnorm',x.shape)\n",
    "        x = self.conv_activation(x)\n",
    "        #print('activation f',x.shape)\n",
    "        x = self.ECA_layer(x) #conv attention\n",
    "        #print('eca',x.shape)\n",
    "        x = self.project(x)\n",
    "        #print(x.shape)\n",
    "        x = self.scale_bias_1(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = x+skip\n",
    "\n",
    "        residual = x\n",
    "        x = self.ffn(x) # ff + gate\n",
    "        x = self.scale_bias_2(x)\n",
    "        x = self.layer_norm_2(x + residual)\n",
    "        return x\n",
    "\n",
    "timepoints = 225\n",
    "representations = 4\n",
    "wavelengths = 283\n",
    "targetWavelengths = 283\n",
    "\n",
    "def fcn():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1000)(x)\n",
    "    #x = tf.keras.layers.Dense(100)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "def cnn1():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    kernelS = 20\n",
    "    for i in range(25):       \n",
    "        x = tf.keras.layers.Conv1D(filters=283, kernel_size=(5), padding='valid')(x)\n",
    "        #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        x = Reshape11()(x) # wavelengths x timepoints\n",
    "        x = tf.keras.layers.Dense(timeP)(x)  # dense on timepoints\n",
    "        x = Reshape11()(x) # timepoints  *  wavelengths\n",
    "\n",
    "    #x = tf.keras.layers.DepthwiseConv1D(kernel_size=5,strides=1,padding='same', depth_multiplier=1,activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(283)(x)\n",
    "    x = Reshape11()(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    #x = tf.keras.layers.Dense(50)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "def cnn2():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    kernelS = 20\n",
    "    for i in range(5):\n",
    "        # depthwise1d filter -> one filter per channel (=wavelength), depth_multiplier tells us how many filters per channel\n",
    "        x = tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='relu')(x)\n",
    "        timeP = timeP - kernelS\n",
    "        \n",
    "        #x = tf.keras.layers.Conv1D(filters=283, kernel_size=(20), padding='valid')(x)\n",
    "        #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        #x = Reshape11()(x) # wavelengths x timepoints\n",
    "        #x = tf.keras.layers.Dense(timeP)(x)  # dense on timepoints\n",
    "        #x = Reshape11()(x) # timepoints  *  wavelengths\n",
    "\n",
    "    #x = tf.keras.layers.DepthwiseConv1D(kernel_size=5,strides=1,padding='same', depth_multiplier=1,activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(283)(x)\n",
    "    x = Reshape11()(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.Dense(50)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "def cnn3():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    kernelS = 20\n",
    "    n_conv=20\n",
    "    depth_cnn = 7\n",
    "    for j in range(depth_cnn):\n",
    "        # depthwise1d filter -> one filter per channel (=wavelength), depth_multiplier tells us how many filters per channel\n",
    "        \n",
    "        out = []\n",
    "        for i in range(5):\n",
    "            x0 = tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='relu')(x)\n",
    "            out.append(x0)\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)(out)\n",
    "        x = tf.keras.layers.Dense(283)(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        #x = tf.keras.layers.Conv1D(filters=283, kernel_size=(20), padding='valid')(x)\n",
    "        #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        #x = Reshape11()(x) # wavelengths x timepoints\n",
    "        #x = tf.keras.layers.Dense(timeP)(x)  # dense on timepoints\n",
    "        #x = Reshape11()(x) # timepoints  *  wavelengths\n",
    "\n",
    "    #x = tf.keras.layers.DepthwiseConv1D(kernel_size=5,strides=1,padding='same', depth_multiplier=1,activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    x = tf.keras.layers.Dense(283)(x)\n",
    "    x = Reshape11()(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    x = tf.keras.layers.Dense(50)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "def cnn2D():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,0:1]\n",
    "    for i in range(3):\n",
    "        # depthwise1d filter -> one filter per channel (=wavelength), depth_multiplier tells us how many filters per channel\n",
    "        #x = tf.keras.layers.DepthwiseConv1D(kernel_size=10,strides=1,padding='valid', depth_multiplier=1,activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same')(x)\n",
    "        x = tf.keras.layers.AveragePooling2D((2,1))(x)\n",
    "        #x = tf.keras.layers.Dense(284)(x)\n",
    "\n",
    "    #x = tf.keras.layers.DepthwiseConv1D(kernel_size=5,strides=1,padding='same', depth_multiplier=1,activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(283)(x)\n",
    "    #x = Reshape3()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1000)(x)\n",
    "    #x = tf.keras.layers.Dense(100)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "def squeezeformer():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    conv_filter = 15\n",
    "    dim=timepoints\n",
    "    x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    x = Reshape11()(x) # wavelengths x timepoints\n",
    "    x = Conv1DBlockSqueezeformer(dim,conv_filter)(x)  # squeeezefilter out columns of time, might not be super effective tbh\n",
    "\n",
    "    for _ in range(10):\n",
    "        x = Reshape11()(x) # timepoints*wavelengths\n",
    "        x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "        x = Reshape11()(x) # wavelengths x timepoints\n",
    "        x = Conv1DBlockSqueezeformer(dim,conv_filter)(x)  # squeeezefilter out columns of time, might not be super effective tbh\n",
    "\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "def transformer():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    conv_filter = 15\n",
    "    dim=timepoints\n",
    "    x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    x = Reshape11()(x) # wavelengths x timepoints\n",
    "    x = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "    x = Reshape11()(x) # timepoints x wavelengths\n",
    "\n",
    "    x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    x = Reshape11()(x) # wavelengths x timepoints\n",
    "    x = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "    x = Reshape11()(x) # timepoints x wavelengths\n",
    "\n",
    "    #x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    #x = Reshape11()(x) # wavelengths x timepoints\n",
    "    #x = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "    #x = Reshape11()(x) # timepoints x wavelengths\n",
    "#\n",
    "    #x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    #x = Reshape11()(x) # wavelengths x timepoints\n",
    "    #x = tf.keras.layers.Dense(75, activation='linear')(x)\n",
    "    #x = Reshape11()(x) # timepoints x wavelengths\n",
    "\n",
    "    x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    x = Reshape11()(x) # wavelengths x timepoints\n",
    "    x = tf.keras.layers.Dense(75, activation='linear')(x)\n",
    "    x = Reshape11()(x) # timepoints x wavelengths\n",
    "    \n",
    "    x = TransformerEncoder(wavelengths, 4, wavelengths*4)(x)\n",
    "    x = Reshape11()(x) # wavelengths x timepoints\n",
    "    x = tf.keras.layers.Dense(15, activation='linear')(x)\n",
    "\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model\n",
    "\n",
    "class transf1d(tf.keras.layers.Layer):\n",
    "    def __init__(self, inputDim,embed_dim, num_heads, feed_forward_dim, reshape=True):\n",
    "        super().__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=inputDim//num_heads)\n",
    "        #self.ffn = GLUMlp(feed_forward_dim, embed_dim)\n",
    "        self.ffn2 = tf.keras.layers.Dense(feed_forward_dim)\n",
    "        self.reshape1 = Reshape11()\n",
    "        self.reshape2 = Reshape11()\n",
    "        self.reshape = reshape\n",
    "    def call(self, x, training = None):\n",
    "        residual = x\n",
    "        x = self.att(x,x)\n",
    "        x = x + residual\n",
    "        if self.reshape:\n",
    "            x = self.reshape1(x)\n",
    "        #x = self.ffn(x)\n",
    "        x = self.ffn2(x)\n",
    "        #x = self.reshape2()(x)\n",
    "        return x\n",
    "class att1d(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim):\n",
    "        super().__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim//num_heads)\n",
    "    def call(self, x, training = None):\n",
    "        residual = x\n",
    "        x = self.att(x,x)\n",
    "        x = x + residual\n",
    "        return x\n",
    "    \n",
    "class custConv1dDepthwise(tf.keras.layers.Layer):\n",
    "    def __init__(self, arr, meanInit=True):\n",
    "        super().__init__()\n",
    "        self.arr = arr\n",
    "        self.maxSlidingWindow = max(self.arr)\n",
    "        if meanInit:\n",
    "            self.convArr = [tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='linear', depthwise_initializer=tf.keras.initializers.Constant(1.0 / kernelS)) for kernelS in self.arr]\n",
    "        else:\n",
    "            self.convArr = [tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1) for kernelS in self.arr]\n",
    "    def call(self, x, training = None):\n",
    "        #print(x.shape)\n",
    "        outDim = x.shape[1] - self.maxSlidingWindow +1\n",
    "        out=[]\n",
    "        for i in range(len(self.arr)):  \n",
    "            #print(x.shape)\n",
    "            x0=self.convArr[i](x)\n",
    "            thisOutDim = x.shape[1] - self.arr[i] +1 \n",
    "            startIdx = int((thisOutDim - outDim)/2)\n",
    "            x0 = x0[:,startIdx:startIdx+outDim,:]\n",
    "            out.append(x0)\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)(out)\n",
    "        #print('out',x.shape)\n",
    "        return x\n",
    "    \n",
    "class custConv1d(tf.keras.layers.Layer):\n",
    "    def __init__(self, arr, meanInit=True, filters=8):\n",
    "        super().__init__()\n",
    "        self.arr = arr\n",
    "        self.maxSlidingWindow = max(self.arr)\n",
    "        if meanInit:\n",
    "            self.convArr = [tf.keras.layers.Conv1D(filters=filters, kernel_size=(kernelS), padding='valid', kernel_initializer=tf.keras.initializers.Constant(1.0 / kernelS)) for kernelS in self.arr]\n",
    "        else:\n",
    "            self.convArr = [tf.keras.layers.Conv1D(filters=filters, kernel_size=(kernelS), padding='valid') for kernelS in self.arr]\n",
    "    def call(self, x, training = None):\n",
    "        outDim = x.shape[-2] - self.maxSlidingWindow +1\n",
    "        out=[]\n",
    "        for i in range(len(self.arr)):  \n",
    "            x0=self.convArr[i](x)\n",
    "            thisOutDim = x.shape[-2] - self.arr[i] +1 \n",
    "            startIdx = int((thisOutDim - outDim)/2)\n",
    "            x0 = x0[:,startIdx:startIdx+outDim,:]\n",
    "            out.append(x0)\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)(out)\n",
    "        return x\n",
    "\n",
    " \n",
    "def singleWL():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,0:1,1]\n",
    "    timeP = timepoints\n",
    "    kernelS = 30\n",
    "    #out = [x]\n",
    "    if 0:\n",
    "        for i in range(4): \n",
    "            #x = LearnableRollingMean(50)  (x)\n",
    "            x = tf.keras.layers.Conv1D(filters=8, kernel_size=(kernelS), padding='valid')(x)\n",
    "            #x = tf.keras.layers.Conv1D(filters=2, kernel_size=(kernelS), padding='valid', kernel_initializer=tf.keras.initializers.Constant(1.0 / kernelS))(x)\n",
    "            #x = tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='linear')(x)\n",
    "            timeP = timeP - (kernelS-1)\n",
    "            #x = transf1d(embed_dim=timeP, num_heads=4, feed_forward_dim=2*timeP)(x)\n",
    "            #x = Reshape11()(x)\n",
    "            #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "            #out.append(x0)\n",
    "\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    for _ in range(3):\n",
    "        x = custConv1d([30,35,40,45,50,55,60,65], meanInit=False)(x)\n",
    "        #x = tf.keras.layers.Dense(24)(x)\n",
    "        #x = tf.keras.layers.Conv1D(filters=8, kernel_size=(kernelS), padding='valid')(x)\n",
    "        #x = custConv1d([10,30,50])(x)\n",
    "        #print(x.shape)\n",
    "        #x = TransformerEncoder(embed_dim=x.shape[2], num_heads=4, feed_forward_dim=x.shape[2]*2)(x)\n",
    "        #x = tf.keras.layers.Dense(x.shape[2])(x)\n",
    "    #x = att1d(embed_dim=outDim, num_heads=4, feed_forward_dim=2*outDim)(x)\n",
    "    #x = tf.keras.layers.Dense(1000)(x)\n",
    "    #x = Reshape11()(x)\n",
    "    #x = tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='linear')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(5)(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model   \n",
    "\n",
    "def cnn4converges():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([30,50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(2):\n",
    "        x = custConv1dDepthwise([30,50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        #x = custConv1d([5,10,20,30,50], meanInit=False, filters=283)(x)\n",
    "        #x = transf1d(inputDim=5*283,embed_dim=283,num_heads=4, feed_forward_dim=283)(x)\n",
    "        #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(5)(x)\n",
    "    #x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model  \n",
    "\n",
    "def cnn5converges():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(2):\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model  \n",
    "\n",
    "#seems to be very slow\n",
    "def cnn51():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(3):\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = custConv1dDepthwise([20], meanInit=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Reshape11()(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred[:,:,0])\n",
    "    return model  \n",
    "\n",
    "#easily fits one batch\n",
    "# full dataset is harder to fit + has overfitting\n",
    "def cnn52():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([20], meanInit=True)(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(1):\n",
    "        x = custConv1dDepthwise([20], meanInit=False)(x)\n",
    "        x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Dense(2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model   \n",
    "\n",
    "def cnn53():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([20], meanInit=True)(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(3):\n",
    "        x = custConv1dDepthwise([20], meanInit=False)(x)\n",
    "        #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model   \n",
    "\n",
    "def cnn54():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([5], meanInit=True)(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(3):\n",
    "        x = custConv1dDepthwise([5], meanInit=False)(x)\n",
    "        x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model  \n",
    "\n",
    "def cnn55():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    dim = timepoints - 50 +1\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(3):\n",
    "        x = transf1d(inputDim=dim,embed_dim=283,num_heads=4, feed_forward_dim=dim)(x)\n",
    "        x = Reshape11()(x)\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        dim = dim - 50 +1\n",
    "        #x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Reshape11()(x)\n",
    "    for i in range(3):\n",
    "        x = tf.keras.layers.Dense(29, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(40, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(3, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred[:,:,0])\n",
    "    return model  \n",
    "\n",
    "def cnn56():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(2):\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(283, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model \n",
    "    \n",
    "\n",
    "def cnn57():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,0,:]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    dim = timepoints - 50+1\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(10):\n",
    "        x = transf1d(inputDim=4,embed_dim=4, num_heads=4, feed_forward_dim=2*8, reshape=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = custConv1d([12], meanInit=False,filters=4*(i+1))(x)\n",
    "        #x = tf.keras.layers.Dense(4, activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        dim = dim -5+1\n",
    "    \n",
    "    #x = Reshape11()(x)\n",
    "    #x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model   \n",
    "\n",
    "\n",
    "#converges on one batch, potentially on all train data, but doesn't reduce overfitting\n",
    "def cnn6():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(2):\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = Reshape11()(x)\n",
    "   #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred[:,:,0])\n",
    "    return model  \n",
    "\n",
    "def cnn7():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(2):\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(283, activation='relu')(x)\n",
    "    x = Reshape11()(x)\n",
    "   #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred[:,:,0])\n",
    "    return model  \n",
    "# takes forever, no real progress\n",
    "def cnn8():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints - 50 +1\n",
    "    #x = custConv1d([10,30,50])(x)\n",
    "    x = custConv1dDepthwise([50], meanInit=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Dense(283*5, activation='relu')(x)\n",
    "    for i in range(2):\n",
    "        x = custConv1dDepthwise([50], meanInit=False)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        timeP = timeP - 50 +1\n",
    "    #x = TransformerEncoder(embed_dim=283, num_heads=4, feed_forward_dim=2*283)(x) #relations between timepoints\n",
    "    x = Reshape11()(x)\n",
    "    x = TransformerEncoder(embed_dim=timeP, num_heads=4, feed_forward_dim=2*timeP)(x) #relations between wavelengths\n",
    "   #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(3, activation='relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred[:,:,0])\n",
    "    return model  \n",
    "\n",
    "def cnnAttentin():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    timeP = timepoints\n",
    "    kernelS = 50\n",
    "    for i in range(2):       \n",
    "        x = tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='linear')(x)\n",
    "        #x = tf.keras.layers.DepthwiseConv1D(kernel_size=kernelS,strides=1,padding='valid', depth_multiplier=1,activation='linear', depthwise_initializer=tf.keras.initializers.Constant(1.0 / kernelS))(x)\n",
    "        #x = tf.keras.layers.Conv1D(filters=283, kernel_size=(20), padding='valid')(x)\n",
    "        timeP = timeP-(kernelS-1)\n",
    "        out=[]\n",
    "        for wl in range(283):\n",
    "            x0 = x[:,:,wl:wl+1]\n",
    "            x0 = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=5)(x0,x0) + x0\n",
    "            x0 = Reshape11()(x0)\n",
    "            x0 = GLUMlp(timeP*2,timeP)(x0) #expand time and have a gating on it\n",
    "            x0 = Reshape11()(x0)\n",
    "            out.append(x0)\n",
    "        x = tf.keras.layers.Concatenate(axis=-1)(out)\n",
    "\n",
    "        #x = Reshape11()(x)\n",
    "        #print(timeP)\n",
    "        #nreduce=30\n",
    "        #x = GLUMlp(timeP*4, timeP-nreduce)(x) #rduce time dimension\n",
    "        #timeP = timeP-nreduce\n",
    "        #x = Reshape11()(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    #x = TransformerEncoder(timeP, 4, timeP*4)(x) # attention on wavelenghts doesn't work at all!\n",
    "    #x = tf.keras.layers.Conv1D(filters=283, kernel_size=(20), padding='valid')(x)\n",
    "\n",
    "    x = Reshape11()(x)\n",
    "    #x = GLUMlp(timeP*2, int(timeP/2))(x)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #x = tf.keras.layers.Dense(100)(x)\n",
    "    #x = TransformerEncoder(100, 4, 200)(x)\n",
    "    #x = tf.keras.layers.Dense(50)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x_pred)\n",
    "    return model  \n",
    "    return \n",
    "#model = cnnDepthwise() \n",
    "#model = cnn2D() \n",
    "#model= squeezeformer()\n",
    "#model = fcn() \n",
    "#model = cnn1() \n",
    "#model = transformer()\n",
    "#model = cnnAttentin()\n",
    "#model = singleWL()\n",
    "model=cnn57()\n",
    "#model=cnn5converges()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('deviations_model_conv53_2_56.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iter = iter(train_dataset)\n",
    "batch=next(batch_iter)\n",
    "batch1=next(batch_iter)\n",
    "batch2=next(batch_iter)\n",
    "out = model(batch[0])\n",
    "dataset_iterator = iter(test_dataset)\n",
    "test_batch1 = next(dataset_iterator)\n",
    "test_batch2 = next(dataset_iterator)\n",
    "batch[0].dtype ,batch[1].dtype, out.dtype,batch[0].shape ,batch[1].shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maeSingleWL(y_true,y_pred):\n",
    "    y_true=y_true[:,0:1]\n",
    "    #tf.print(y_pred.shape)\n",
    "    #y_pred=tf.reduce_mean(y_pred,axis=-1)\n",
    "    #tf.print(y_true.shape, y_pred.shape)\n",
    "    return tf.reduce_mean(tf.math.abs(y_true-y_pred))\n",
    "\n",
    "def mae(y_true,y_pred):\n",
    "    #tf.print(y_pred, y_true)\n",
    "    #y_pred=tf.reduce_mean(y_pred,axis=-1)\n",
    "    #tf.print(y_true.shape, y_pred.shape)\n",
    "    return tf.reduce_sum(tf.math.abs(y_true-y_pred))\n",
    "\n",
    "maeSingleWL(batch[1],out), mae(batch[1],out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"C:/Users/uic33116/Documents/documents/ariel-data-challenge-2024/training_full_model/deviations_model-{epoch:02d}.weights.h5\",\n",
    "    save_weights_only=True,  # Set to False if you want to save the entire model\n",
    "    save_freq=300 * 4,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(#loss='mae'\n",
    "              loss=maeSingleWL\n",
    "              #loss='mse'#maeSingleWL#'mae'            \n",
    "              #,metrics=[log_likelihood_maxScaling]\n",
    "              #,metrics=['mse']\n",
    "              , optimizer=optimizer)\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    #batch[0],batch[1], #verbose=2,\n",
    "                    #small_train,\n",
    "                    #validation_data=test_dataset,\n",
    "                    validation_data=test_batch1,\n",
    "                    epochs=400, batch_size=batch_size,\n",
    "                    #callbacks=[lr_callback]\n",
    "                    )\n",
    "\n",
    "# batch normalization essential for gradient to travel downstream!\n",
    "# with batch of 12 we converge well to mae ~3.3, mse 57 after ~3000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(small_train))\n",
    "outs = model.predict(b[0])\n",
    "outs,b[1][:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model.predict(test_batch1[0])\n",
    "outs,test_batch1[1][:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(#train_dataset, \n",
    "                    #batch[0],batch[1], #verbose=2,\n",
    "                    small_train,\n",
    "                    #validation_data=test_dataset,\n",
    "                    validation_data=test_batch1,\n",
    "                    epochs=100, batch_size=batch_size,\n",
    "                    #callbacks=[lr_callback]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('deviationModelCnn56_5_75.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict(normData)\n",
    "def calcStats(b, plot=True, display=False):\n",
    "    outputs = model.predict(b[0])\n",
    "    print(outputs.shape)\n",
    "    pred = outputs[:,0:283]\n",
    "\n",
    "    if display:\n",
    "        print(pred[0:10:,0:2,0], b[1][0:10:,0:2])\n",
    "        print(pred[0:10:,0:2,0]*maxLabels, b[1][0:10:,0:2]*maxLabels)\n",
    "\n",
    "    mae = np.sum(np.abs(pred[:,:]-b[1])) / pred.shape[0] / pred.shape[1]\n",
    "    mse = np.sum(np.abs(pred[:,:]-b[1])**2) / pred.shape[0] / pred.shape[1]\n",
    "    print('mae',mae,'mse', mse)\n",
    "    for i in range(outputs.shape[0]):\n",
    "        mae = np.sum(np.abs(pred[i,:]-b[1][i,:])) / pred.shape[1]\n",
    "        mse = np.sum(np.abs(pred[i,:]-b[1][i,:])**2) / pred.shape[1]\n",
    "        print('row',i,'mae',mae,'mse', mse)\n",
    "\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    m = min(100, batch[0].shape[0])\n",
    "    for i in range(m): #range(12):# \n",
    "        fig.add_trace(go.Scatter(y=b[1][i,:]*maxLabels,mode='markers',name=f'gt_{i}',marker=dict(size=3),visible='legendonly'))\n",
    "        fig.add_trace(go.Scatter(y=pred[i,:]*maxLabels,mode='markers',name=f'pred_{i}',marker=dict(size=3)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcStats(next(iter(small_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcStats(test_batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(batch[0])\n",
    "\n",
    "mae = np.sum(np.abs(outputs*100*maxLabels-batch[1][:,0:1]*100*maxLabels)) / outputs.shape[0]\n",
    "mse = np.sum(np.abs(outputs*100*maxLabels-batch[1][:,0:1]*100*maxLabels)**2) / outputs.shape[0]\n",
    "mae1 = np.sum(np.abs(outputs*maxLabels-batch[1][:,0:1]*maxLabels)) / outputs.shape[0]\n",
    "mse1 = np.sum(np.abs(outputs*maxLabels-batch[1][:,0:1]*maxLabels)**2) / outputs.shape[0]\n",
    "mae,mae1, outputs, batch[1][:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputst = model.predict(test_batch[0])\n",
    "\n",
    "mae = np.sum(np.abs(outputst*100*maxLabels-test_batch[1][:,0:1]*100*maxLabels)) / outputs.shape[0]\n",
    "mse = np.sum(np.abs(outputst*100*maxLabels-test_batch[1][:,0:1]*100*maxLabels)**2) / outputs.shape[0]\n",
    "mae1 = np.sum(np.abs(outputst*maxLabels-test_batch[1][:,0:1]*maxLabels)) / outputs.shape[0]\n",
    "mse1 = np.sum(np.abs(outputs*maxLabels-test_batch[1][:,0:1]*maxLabels)**2) / outputs.shape[0]\n",
    "mae,mae1, outputst, test_batch[1][:,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchid = 2\n",
    "wl = 0\n",
    "x = batch[0][batchid:batchid+1,:,:,1]  \n",
    "print(x.shape)  \n",
    "fig = plt.figure()\n",
    "plt.plot(x[0,:,wl])\n",
    "plt.title(f'input')\n",
    "plt.show()\n",
    "\n",
    "for layers in range(len(model.layers)-1):\n",
    "    x = model.layers[layers+1](x)\n",
    "    print(x.shape)\n",
    "    \n",
    "    if len(x.shape)>=3:\n",
    "        if len(x.shape) == 4:\n",
    "            for i in range(x.shape[-1]):\n",
    "                fig = plt.figure()\n",
    "                plt.plot(x[0,:,wl,i])\n",
    "                plt.title(f'layer {layers+1}')\n",
    "                plt.show()\n",
    "        else:\n",
    "            fig = plt.figure()\n",
    "            if x.shape[2] == 283:\n",
    "                plt.plot(x[0,:,wl])\n",
    "            else:\n",
    "                if x.shape[2] == 1:\n",
    "                    print(x[:,wl,:], batch[1][batchid:batchid+1,0:1])\n",
    "                else:\n",
    "                    plt.plot(x[0,wl,:])\n",
    "            plt.title(f'layer {layers+1}')\n",
    "            plt.show()\n",
    "    else:\n",
    "        if x.shape[1] >1:\n",
    "            fig=plt.figure()\n",
    "            plt.plot(x[0])\n",
    "            plt.title(f'layer{layers+1}')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(x, batch[1][batchid:batchid+1,0:1])\n",
    "#print(model.layers[2].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchid = 0\n",
    "wl = 0\n",
    "x = batch[0][batchid:batchid+1,:,:,1]  \n",
    "print(x.shape)  \n",
    "fig = plt.figure()\n",
    "plt.plot(x[0,:,wl])\n",
    "plt.title(f'input')\n",
    "plt.show()\n",
    "\n",
    "x = x[:,:,wl:wl+1]\n",
    "for layers in range(len(model.layers)-1):\n",
    "    print(x.shape)\n",
    "    x = model.layers[layers+1](x)\n",
    "    print(x.shape)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    if len(x.shape) == 3:\n",
    "        for i in range(x.shape[2]):\n",
    "            fig = plt.figure()\n",
    "            plt.plot(np.reshape(x[0,:,i],(-1)))\n",
    "            plt.title(f'layer {layers+1}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot(x[0,:])\n",
    "        plt.title(f'layer {layers+1}')\n",
    "        plt.show()\n",
    "#print(model.layers[2].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(batch[0][batchid,:,wl,1]  )\n",
    "plt.title(f'input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0][batchid:batchid+1,:,wl,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[1])\n",
    "for i in range(4):\n",
    "    fig=plt.figure()\n",
    "    plt.plot(x[i,:,0])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
