{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "from astropy.stats import sigma_clip\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADC_convert(signal, gain, offset):\n",
    "    signal = signal.astype(np.float64)\n",
    "    signal /= gain\n",
    "    signal += offset\n",
    "    return signal\n",
    "\n",
    "def mask_hot_dead(signal, dead, dark):\n",
    "    hot = sigma_clip(\n",
    "        dark, sigma=5, maxiters=5\n",
    "    ).mask\n",
    "    hot = np.tile(hot, (signal.shape[0], 1, 1))\n",
    "    dead = np.tile(dead, (signal.shape[0], 1, 1))\n",
    "    signal = np.ma.masked_where(dead, signal)\n",
    "    signal = np.ma.masked_where(hot, signal)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def apply_linear_corr(linear_corr,clean_signal):\n",
    "    linear_corr = np.flip(linear_corr, axis=0)\n",
    "    for x, y in itertools.product(\n",
    "                range(clean_signal.shape[1]), range(clean_signal.shape[2])\n",
    "            ):\n",
    "        poli = np.poly1d(linear_corr[:, x, y])\n",
    "        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n",
    "    return clean_signal\n",
    "\n",
    "def clean_dark(signal, dead, dark, dt):\n",
    "\n",
    "    dark = np.ma.masked_where(dead, dark)\n",
    "    dark = np.tile(dark, (signal.shape[0], 1, 1))\n",
    "\n",
    "    signal -= dark* dt[:, np.newaxis, np.newaxis]\n",
    "    return signal\n",
    "\n",
    "def get_cds(signal):\n",
    "    cds = signal[:,1::2,:,:] - signal[:,::2,:,:]\n",
    "    return cds\n",
    "\n",
    "def bin_obs(cds_signal,binning):\n",
    "    cds_transposed = cds_signal.transpose(0,1,3,2)\n",
    "    cds_binned = np.zeros((cds_transposed.shape[0], cds_transposed.shape[1]//binning, cds_transposed.shape[2], cds_transposed.shape[3]))\n",
    "    for i in range(cds_transposed.shape[1]//binning):\n",
    "        cds_binned[:,i,:,:] = np.sum(cds_transposed[:,i*binning:(i+1)*binning,:,:], axis=1)\n",
    "    return cds_binned\n",
    "\n",
    "def correct_flat_field(flat,dead, signal):\n",
    "    flat = flat.transpose(1, 0)\n",
    "    dead = dead.transpose(1, 0)\n",
    "    flat = np.ma.masked_where(dead, flat)\n",
    "    flat = np.tile(flat, (signal.shape[0], 1, 1))\n",
    "    signal = signal / flat\n",
    "    return signal\n",
    "\n",
    "def get_cds_origial(signal):\n",
    "    \"\"\"\n",
    "    calcs difference in time becuase the detector is read twice, once in the beginning and once in the end of the measurement, the difference is what's measured\n",
    "    \"\"\"\n",
    "    cds = signal[1::2,:,:] - signal[::2,:,:]\n",
    "    return cds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135000, 32, 32)\n",
      "(135000, 12, 12)\n",
      "t1 0.1487279585246287\n",
      "t2 0.13750977556198257\n",
      "t3 0.42932391667551956\n",
      "t4 0.04308983421711504\n",
      "t5 0.04686971473161475\n",
      "t6 0.01077246891056976\n",
      "t7 0.07678232855527897\n",
      "t8 0.005850517337125006\n",
      "t9 0.008335260811693362\n",
      "t10 0.09273822467447226\n",
      "11.510809183120728\n"
     ]
    }
   ],
   "source": [
    "planet_id = 612015401\n",
    "\n",
    "path_folder = \"\"\n",
    "\n",
    "train_adc_info = pd.read_csv(os.path.join(path_folder, 'train_adc_info.csv'))\n",
    "train_adc_info = train_adc_info.set_index('planet_id')\n",
    "axis_info = pd.read_parquet(os.path.join(path_folder,'axis_info.parquet'))\n",
    "\n",
    "DO_MASK = True  # filter out non responsive pixels\n",
    "DO_THE_NL_CORR = True # most time consuming step, you can choose to ignore it for rapid prototyping, nonlinear correction due to artefacts when reading pixels\n",
    "DO_DARK = True  # dark current is accumulating over time in the pixels, need to compensate that (seems like integration artefact)\n",
    "DO_FLAT = True  # pixel to pixel variation correction (e.g. how pixels respond differently when illuminated uniformly)\n",
    "TIME_BINNING = False  #do a time binning on choosen frequency\n",
    "\n",
    "cut_inf, cut_sup = 39, 321\n",
    "l = cut_sup - cut_inf\n",
    "\n",
    "t0 = time.time()\n",
    "cut_inf, cut_sup = 39, 321\n",
    "l = cut_sup - cut_inf\n",
    "AIRS_CH0_clean = np.zeros((1, 11250, 32, l))\n",
    "FGS1_clean = np.zeros((1, 135000, 12, 12))\n",
    "df = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/AIRS-CH0_signal.parquet'))\n",
    "signal = df.values.astype(np.float64).reshape((df.shape[0], 32, 356))\n",
    "gain = train_adc_info['AIRS-CH0_adc_gain'].loc[planet_id]\n",
    "offset = train_adc_info['AIRS-CH0_adc_offset'].loc[planet_id]\n",
    "signal = ADC_convert(signal, gain, offset)\n",
    "dt_airs = axis_info['AIRS-CH0-integration_time'].dropna().values\n",
    "dt_airs[1::2] += 0.1\n",
    "chopped_signal = signal[:, :, cut_inf:cut_sup]\n",
    "airs_original = chopped_signal\n",
    "del signal, df\n",
    "# CLEANING THE DATA: AIRS\n",
    "flat = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "dark = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/AIRS-CH0_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "dead_airs = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/AIRS-CH0_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "linear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/AIRS-CH0_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 356))[:, :, cut_inf:cut_sup]\n",
    "t1 = time.time()\n",
    "if DO_MASK:\n",
    "    chopped_signal = mask_hot_dead(chopped_signal, dead_airs, dark)\n",
    "    AIRS_CH0_clean[0] = chopped_signal\n",
    "else:\n",
    "    AIRS_CH0_clean[0] = chopped_signal\n",
    "t2 = time.time()\n",
    "if DO_THE_NL_CORR: \n",
    "    linear_corr_signal = apply_linear_corr(linear_corr,AIRS_CH0_clean[0])\n",
    "    AIRS_CH0_clean[0] = linear_corr_signal\n",
    "del linear_corr\n",
    "t3 = time.time()\n",
    "if DO_DARK: \n",
    "    cleaned_signal = clean_dark(AIRS_CH0_clean[0], dead_airs, dark,dt_airs)\n",
    "    AIRS_CH0_clean[0] = cleaned_signal\n",
    "else: \n",
    "    pass\n",
    "del dark\n",
    "t4 = time.time()\n",
    "df = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/FGS1_signal.parquet'))\n",
    "fgs_signal = df.values.astype(np.float64).reshape((df.shape[0], 32, 32))\n",
    "print(fgs_signal.shape)\n",
    "fgs_signal = fgs_signal[:,10:22,10:22]\n",
    "print(fgs_signal.shape)\n",
    "FGS1_gain = train_adc_info['FGS1_adc_gain'].loc[planet_id]\n",
    "FGS1_offset = train_adc_info['FGS1_adc_offset'].loc[planet_id]\n",
    "fgs_signal = ADC_convert(fgs_signal, FGS1_gain, FGS1_offset)\n",
    "dt_fgs1 = np.ones(len(fgs_signal))*0.1  ## please refer to data documentation for more information\n",
    "dt_fgs1[1::2] += 0.1\n",
    "chopped_FGS1 = fgs_signal\n",
    "fgs_original = chopped_FGS1\n",
    "del fgs_signal, df\n",
    "# CLEANING THE DATA: FGS1\n",
    "dark = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/FGS1_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "dark = dark[10:22,10:22]\n",
    "dead_fgs1 = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/FGS1_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "dead_fgs1 = dead_fgs1[10:22,10:22]\n",
    "linear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/FGS1_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 32))\n",
    "linear_corr = linear_corr[:,10:22,10:22]\n",
    "t5 = time.time()\n",
    "if DO_MASK:\n",
    "    chopped_FGS1 = mask_hot_dead(chopped_FGS1, dead_fgs1, dark)\n",
    "    FGS1_clean[0] = chopped_FGS1\n",
    "else:\n",
    "    FGS1_clean[0] = chopped_FGS1\n",
    "t6 = time.time()\n",
    "if DO_THE_NL_CORR: \n",
    "    linear_corr_signal = apply_linear_corr(linear_corr,FGS1_clean[0])\n",
    "    FGS1_clean[0,:, :, :] = linear_corr_signal\n",
    "del linear_corr\n",
    "t7 = time.time()\n",
    "if DO_DARK: \n",
    "    cleaned_signal = clean_dark(FGS1_clean[0], dead_fgs1, dark,dt_fgs1)\n",
    "    FGS1_clean[0] = cleaned_signal\n",
    "else: \n",
    "    pass\n",
    "del dark \n",
    "t8 = time.time()\n",
    "AIRS_cds = get_cds(AIRS_CH0_clean)\n",
    "FGS1_cds = get_cds(FGS1_clean)\n",
    "t9 = time.time()\n",
    "## (Optional) calc diff of data between two timestamps\n",
    "if TIME_BINNING:\n",
    "    AIRS_cds_binned = bin_obs(AIRS_cds,binning=30)\n",
    "    FGS1_cds_binned = bin_obs(FGS1_cds,binning=30*12)\n",
    "else:\n",
    "    AIRS_cds = AIRS_cds.transpose(0,1,3,2) ## this is important to make it consistent for flat fielding, but you can always change it\n",
    "    AIRS_cds_binned = AIRS_cds\n",
    "    FGS1_cds = FGS1_cds.transpose(0,1,3,2)\n",
    "    FGS1_cds_binned = FGS1_cds\n",
    "del AIRS_cds, FGS1_cds\n",
    "flat_airs = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "flat_fgs = pd.read_parquet(os.path.join(path_folder,f'train/{planet_id}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "flat_fgs = flat_fgs[10:22,10:22]\n",
    "if DO_FLAT:\n",
    "    corrected_AIRS_cds_binned = correct_flat_field(flat_airs,dead_airs, AIRS_cds_binned[0])\n",
    "    AIRS_cds_binned[0] = corrected_AIRS_cds_binned\n",
    "    corrected_FGS1_cds_binned = correct_flat_field(flat_fgs,dead_fgs1, FGS1_cds_binned[0])\n",
    "    FGS1_cds_binned[0] = corrected_FGS1_cds_binned\n",
    "else:\n",
    "    pass\n",
    "AIRS_cds_original = np.expand_dims(get_cds_origial(airs_original), axis=0).transpose(0,1,3,2)\n",
    "FGS1_cds_original = np.expand_dims(get_cds_origial(fgs_original), axis=0).transpose(0,1,3,2)\n",
    "t10 = time.time()\n",
    "deltaT = t10-t0\n",
    "print('t1',(t1-t0)/deltaT)\n",
    "print('t2',(t2-t1)/deltaT)\n",
    "print('t3',(t3-t2)/deltaT)\n",
    "print('t4',(t4-t3)/deltaT)\n",
    "print('t5',(t5-t4)/deltaT)\n",
    "print('t6',(t6-t5)/deltaT)\n",
    "print('t7',(t7-t6)/deltaT)\n",
    "print('t8',(t8-t7)/deltaT)\n",
    "print('t9',(t9-t8)/deltaT)\n",
    "print('t10',(t10-t9)/deltaT)\n",
    "print(deltaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRS_cds_binned.shape, FGS1_cds_binned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(AIRS_cds_binned, axis = 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800 mb for just airs full data vs 120mb parquet file vs 25mb when summed along wavelength\n",
    "# 1gb for fsg data vs 120mb parquet vs. 33mb summed along wavelength\n",
    "\n",
    "np.savez('airs.npz', a=np.sum(FGS1_cds_binned, axis = 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
