{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "from astropy.stats import sigma_clip\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADC_convert(signal, gain, offset):\n",
    "    signal = signal.astype(np.float64)\n",
    "    signal /= gain\n",
    "    signal += offset\n",
    "    return signal\n",
    "\n",
    "def mask_hot_dead(signal, dead, dark):\n",
    "    hot = sigma_clip(\n",
    "        dark, sigma=5, maxiters=5\n",
    "    ).mask\n",
    "    hot = np.tile(hot, (signal.shape[0], 1, 1))\n",
    "    dead = np.tile(dead, (signal.shape[0], 1, 1))\n",
    "    signal = np.ma.masked_where(dead, signal)\n",
    "    signal = np.ma.masked_where(hot, signal)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def apply_linear_corr(linear_corr,clean_signal):\n",
    "    linear_corr = np.flip(linear_corr, axis=0)\n",
    "    for x, y in itertools.product(\n",
    "                range(clean_signal.shape[1]), range(clean_signal.shape[2])\n",
    "            ):\n",
    "        poli = np.poly1d(linear_corr[:, x, y])\n",
    "        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n",
    "    return clean_signal\n",
    "\n",
    "def clean_dark(signal, dead, dark, dt):\n",
    "\n",
    "    dark = np.ma.masked_where(dead, dark)\n",
    "    dark = np.tile(dark, (signal.shape[0], 1, 1))\n",
    "\n",
    "    signal -= dark* dt[:, np.newaxis, np.newaxis]\n",
    "    return signal\n",
    "\n",
    "def get_cds(signal):\n",
    "    cds = signal[:,1::2,:,:] - signal[:,::2,:,:]\n",
    "    return cds\n",
    "\n",
    "def bin_obs(cds_signal,binning):\n",
    "    cds_transposed = cds_signal.transpose(0,1,3,2)\n",
    "    cds_binned = np.zeros((cds_transposed.shape[0], cds_transposed.shape[1]//binning, cds_transposed.shape[2], cds_transposed.shape[3]))\n",
    "    for i in range(cds_transposed.shape[1]//binning):\n",
    "        cds_binned[:,i,:,:] = np.sum(cds_transposed[:,i*binning:(i+1)*binning,:,:], axis=1)\n",
    "    return cds_binned\n",
    "\n",
    "def correct_flat_field(flat,dead, signal):\n",
    "    flat = flat.transpose(1, 0)\n",
    "    dead = dead.transpose(1, 0)\n",
    "    flat = np.ma.masked_where(dead, flat)\n",
    "    flat = np.tile(flat, (signal.shape[0], 1, 1))\n",
    "    signal = signal / flat\n",
    "    return signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 612015401\n",
    "\n",
    "path_folder = \"\"\n",
    "\n",
    "train_adc_info = pd.read_csv(os.path.join(path_folder, 'train_adc_info.csv'))\n",
    "train_adc_info = train_adc_info.set_index('planet_id')\n",
    "axis_info = pd.read_parquet(os.path.join(path_folder,'axis_info.parquet'))\n",
    "\n",
    "DO_MASK = True  # filter out non responsive pixels\n",
    "DO_THE_NL_CORR = True # most time consuming step, you can choose to ignore it for rapid prototyping, nonlinear correction due to artefacts when reading pixels\n",
    "DO_DARK = True  # dark current is accumulating over time in the pixels, need to compensate that (seems like integration artefact)\n",
    "DO_FLAT = True  # pixel to pixel variation correction (e.g. how pixels respond differently when illuminated uniformly)\n",
    "TIME_BINNING = False  #do a time binning on choosen frequency\n",
    "\n",
    "cut_inf, cut_sup = 39, 321\n",
    "l = cut_sup - cut_inf\n",
    "\n",
    "AIRS_CH0_clean = np.zeros((1, 11250, 32, l))\n",
    "FGS1_clean = np.zeros((1, 135000, 32, 32))\n",
    "\n",
    "df = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_signal.parquet'))\n",
    "signal = df.values.reshape((df.shape[0], 32, 356))\n",
    "gain = train_adc_info['AIRS-CH0_adc_gain'].loc[image_id]\n",
    "offset = train_adc_info['AIRS-CH0_adc_offset'].loc[image_id]\n",
    "signal = ADC_convert(signal, gain, offset)\n",
    "dt_airs = axis_info['AIRS-CH0-integration_time'].dropna().values\n",
    "chopped_signal = signal[:, :, cut_inf:cut_sup]\n",
    "del signal, df\n",
    "\n",
    "# CLEANING THE DATA: AIRS\n",
    "flat = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "dark = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "dead_airs = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "linear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 356))[:, :, cut_inf:cut_sup]\n",
    "\n",
    "if DO_MASK:\n",
    "    chopped_signal = mask_hot_dead(chopped_signal, dead_airs, dark)\n",
    "    AIRS_CH0_clean[0] = chopped_signal\n",
    "else:\n",
    "    AIRS_CH0_clean[0] = chopped_signal\n",
    "\n",
    "if DO_THE_NL_CORR: \n",
    "    linear_corr_signal = apply_linear_corr(linear_corr,AIRS_CH0_clean[0])\n",
    "    AIRS_CH0_clean[0] = linear_corr_signal\n",
    "del linear_corr\n",
    "\n",
    "if DO_DARK: \n",
    "    cleaned_signal = clean_dark(AIRS_CH0_clean[0], dead_airs, dark,dt_airs)\n",
    "    AIRS_CH0_clean[0] = cleaned_signal\n",
    "else: \n",
    "    pass\n",
    "del dark\n",
    "\n",
    "df = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_signal.parquet'))\n",
    "fgs_signal = df.values.reshape((df.shape[0], 32, 32))\n",
    "FGS1_gain = train_adc_info['FGS1_adc_gain'].loc[image_id]\n",
    "FGS1_offset = train_adc_info['FGS1_adc_offset'].loc[image_id]\n",
    "fgs_signal = ADC_convert(fgs_signal, FGS1_gain, FGS1_offset)\n",
    "dt_fgs1 = np.ones(len(fgs_signal))*0.1  ## please refer to data documentation for more information\n",
    "chopped_FGS1 = fgs_signal\n",
    "\n",
    "del fgs_signal, df\n",
    "\n",
    "# CLEANING THE DATA: FGS1\n",
    "flat = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "dark = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "dead_fgs1 = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "linear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 32))\n",
    "\n",
    "if DO_MASK:\n",
    "    chopped_FGS1 = mask_hot_dead(chopped_FGS1, dead_fgs1, dark)\n",
    "    FGS1_clean[0] = chopped_FGS1\n",
    "else:\n",
    "    FGS1_clean[0] = chopped_FGS1\n",
    "\n",
    "if DO_THE_NL_CORR: \n",
    "    linear_corr_signal = apply_linear_corr(linear_corr,FGS1_clean[0])\n",
    "    FGS1_clean[0,:, :, :] = linear_corr_signal\n",
    "del linear_corr\n",
    "\n",
    "if DO_DARK: \n",
    "    cleaned_signal = clean_dark(FGS1_clean[0], dead_fgs1, dark,dt_fgs1)\n",
    "    FGS1_clean[0] = cleaned_signal\n",
    "else: \n",
    "    pass\n",
    "del dark \n",
    "\n",
    "# SAVE DATA AND FREE SPACE\n",
    "#AIRS_cds = get_cds(AIRS_CH0_clean)\n",
    "#FGS1_cds = get_cds(FGS1_clean)\n",
    "\n",
    "#del AIRS_CH0_clean, FGS1_clean\n",
    "\n",
    "## (Optional) Time Binning to reduce space\n",
    "if TIME_BINNING:\n",
    "    AIRS_cds_binned = bin_obs(AIRS_CH0_clean,binning=30)\n",
    "    FGS1_cds_binned = bin_obs(FGS1_clean,binning=30*12)\n",
    "else:\n",
    "    AIRS_cds = AIRS_CH0_clean.transpose(0,1,3,2) ## this is important to make it consistent for flat fielding, but you can always change it\n",
    "    AIRS_cds_binned = AIRS_cds\n",
    "    FGS1_cds = FGS1_clean.transpose(0,1,3,2)\n",
    "    FGS1_cds_binned = FGS1_cds\n",
    "\n",
    "del AIRS_cds, FGS1_cds\n",
    "\n",
    "flat_airs = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
    "flat_fgs = pd.read_parquet(os.path.join(path_folder,f'train/{image_id}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\n",
    "if DO_FLAT:\n",
    "    corrected_AIRS_cds_binned = correct_flat_field(flat_airs,dead_airs, AIRS_cds_binned[0])\n",
    "    AIRS_cds_binned[0] = corrected_AIRS_cds_binned\n",
    "    corrected_FGS1_cds_binned = correct_flat_field(flat_fgs,dead_fgs1, FGS1_cds_binned[0])\n",
    "    FGS1_cds_binned[0] = corrected_FGS1_cds_binned\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRS_cds_binned.shape, FGS1_cds_binned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(AIRS_cds_binned, axis = 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800 mb for just airs full data vs 120mb parquet file vs 25mb when summed along wavelength\n",
    "# 1gb for fsg data vs 120mb parquet vs. 33mb summed along wavelength\n",
    "\n",
    "np.savez('airs.npz', a=np.sum(FGS1_cds_binned, axis = 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
