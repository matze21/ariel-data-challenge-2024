{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf0 = pd.read_csv(\"train_labels.csv\")\n",
    "labelDf0 = labelDf0.set_index('planet_id')\n",
    "labelDf0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "files = glob.glob(os.path.join('train/', '*/*'))\n",
    "stars = []\n",
    "for file in files:\n",
    "    file_name = file.split('\\\\')[1]\n",
    "    stars.append(file_name)\n",
    "stars = np.unique(stars)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def split_star_list(file_list, test_ratio=0.6):\n",
    "    random.shuffle(file_list)\n",
    "    split_index = int(len(file_list) * (1 - test_ratio))\n",
    "    train_files = file_list[:split_index]\n",
    "    test_files = file_list[split_index:]\n",
    "    return train_files, test_files\n",
    "\n",
    "train_stars, test_stars = split_star_list(stars)\n",
    "\n",
    "labelDf = pd.read_csv(\"train_labels.csv\")\n",
    "labelDf = labelDf.set_index('planet_id')\n",
    "meanLabels = np.mean(labelDf.mean())\n",
    "stdLabels = np.std(labelDf.std())\n",
    "maxLabels = np.max(labelDf.max())\n",
    "minLabels = np.min(labelDf.min())\n",
    "\n",
    "trainLabels = labelDf.loc[[int(star) for star in train_stars]]\n",
    "meanTrainLabels = np.mean(trainLabels.mean())\n",
    "stdTrainLabels = np.std(trainLabels.std())\n",
    "maxTrainLabels = np.max(trainLabels.max())\n",
    "minTrainLabels = np.min(trainLabels.min())\n",
    "\n",
    "for col in labelDf.columns:\n",
    "    labelDf.loc[:,col] = (labelDf[col]) / (maxTrainLabels)\n",
    "\n",
    "# normalize over time and all samples, so we have a mean and a std dev per wavelength for all samples\n",
    "def calcMeanAndStdOfTrain(train_stars):\n",
    "    i = 0\n",
    "    for star in train_stars:\n",
    "        file_path = 'train/'+str(star)+'/combined.npz'\n",
    "        with np.load(file_path) as data:\n",
    "            x = data['a'][0,:,0:283,:]\n",
    "            if i ==0:\n",
    "                mean = np.mean(x,axis=(0))\n",
    "                sumS = np.sum(x**2,axis=0)\n",
    "            else:\n",
    "                mean = mean + np.mean(x, axis=(0))\n",
    "                sumS += np.sum(x**2,axis=0)\n",
    "            i=i+1\n",
    "    meanTrain = mean / i\n",
    "    stdTrain = np.sqrt(sumS / (i*x.shape[0]) - meanTrain**2)    \n",
    "    return meanTrain, stdTrain\n",
    "meanTrain, stdTrain = calcMeanAndStdOfTrain(train_stars)\n",
    "\n",
    "def normalize_over_train(features, labels):\n",
    "    features = (features - meanTrain) / (stdTrain + 1e-6)\n",
    "    return features, labels\n",
    "\n",
    "# normalize over time per samples, so we have a mean and a std dev per wavelength for all samples\n",
    "def calcMeanAndStdOfTrainPerStar(x):\n",
    "    mean = np.mean(x,axis=(0))\n",
    "    sumS = np.sum(x**2,axis=0)\n",
    "    stdTrain = np.sqrt(sumS / (x.shape[0]) - mean**2)    \n",
    "    return mean, stdTrain\n",
    "def normalize_per_sample(features, labels):\n",
    "    m,s = calcMeanAndStdOfTrainPerStar(features)\n",
    "    features = (features) / (s + 1e-6)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_npz(star):\n",
    "    integer_value = tf.strings.to_number(star, out_type=tf.int64)\n",
    "    python_int = integer_value.numpy()\n",
    "\n",
    "    file_path = 'train/'+str(python_int)+'/combined.npz'\n",
    "    try:\n",
    "        with np.load(file_path) as data:\n",
    "            features = data['a'][0,:,0:283,:]\n",
    "            labels = labelDf.loc[python_int].to_numpy()\n",
    "            features = np.reshape(features,(-1,25,283,4))\n",
    "            features = np.mean(features,axis=1)\n",
    "            #features, labels = normalize_per_sample(features,labels)\n",
    "            features, labels = normalize_over_train(features,labels)\n",
    "            return features, labels\n",
    "    except Exception as e:\n",
    "        print(\"Error loading file:\", e, python_int)\n",
    "    \n",
    "\n",
    "def create_dataset(star_list, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(star_list)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(star_list))\n",
    "    def load_and_process(x):\n",
    "        features, labels = tf.py_function(\n",
    "            func=load_npz,\n",
    "            inp=[x],\n",
    "            Tout=[tf.float64, tf.float32]\n",
    "        )\n",
    "        return features, labels\n",
    "\n",
    "    dataset = dataset.map(load_and_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(lambda x, y: (tf.ensure_shape(x,tf.TensorShape([225, 283, 4])), tf.ensure_shape(y, tf.TensorShape([283])))) #5625\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('helpers_origiData_meanPred.npz',meanTrain=meanTrain, stdTrain=stdTrain,meanLabels=meanLabels,stdLabels=stdLabels,maxTrainLabels=maxTrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = create_dataset(train_stars, batch_size, shuffle=True)\n",
    "test_dataset = create_dataset(test_stars, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean_of_wavelengths │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">284</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">meanOfWavelengths</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,408</span> │ mean_of_waveleng… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv1D</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling1d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ depthwise_conv1d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">284</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">161,596</span> │ average_pooling1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,408</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv1D</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling1d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ depthwise_conv1d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">284</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">161,596</span> │ average_pooling1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,408</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv1D</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling1d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ depthwise_conv1d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">284</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">161,596</span> │ average_pooling1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">568</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,408</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv1D</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">161,027</span> │ depthwise_conv1d… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape11           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape11</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,000</span> │ reshape11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">100,100</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape2</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m225\u001b[0m, \u001b[38;5;34m283\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m225\u001b[0m, \u001b[38;5;34m283\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean_of_wavelengths │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m225\u001b[0m, \u001b[38;5;34m284\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mmeanOfWavelengths\u001b[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m225\u001b[0m, \u001b[38;5;34m568\u001b[0m)  │      \u001b[38;5;34m3,408\u001b[0m │ mean_of_waveleng… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv1D\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling1d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m568\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ depthwise_conv1d… │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m284\u001b[0m)  │    \u001b[38;5;34m161,596\u001b[0m │ average_pooling1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m568\u001b[0m)  │      \u001b[38;5;34m3,408\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDepthwiseConv1D\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling1d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m568\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ depthwise_conv1d… │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m284\u001b[0m)   │    \u001b[38;5;34m161,596\u001b[0m │ average_pooling1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m568\u001b[0m)   │      \u001b[38;5;34m3,408\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDepthwiseConv1D\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling1d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m568\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ depthwise_conv1d… │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m284\u001b[0m)   │    \u001b[38;5;34m161,596\u001b[0m │ average_pooling1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv1d_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m568\u001b[0m)   │      \u001b[38;5;34m3,408\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDepthwiseConv1D\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m283\u001b[0m)   │    \u001b[38;5;34m161,027\u001b[0m │ depthwise_conv1d… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape11           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m, \u001b[38;5;34m28\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mReshape11\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m, \u001b[38;5;34m1000\u001b[0m) │     \u001b[38;5;34m29,000\u001b[0m │ reshape11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m100,100\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │        \u001b[38;5;34m101\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │        \u001b[38;5;34m101\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape2 (\u001b[38;5;33mReshape2\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m, \u001b[38;5;34m2\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,749</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m788,749\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,749</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m788,749\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Reshape1(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0,2,1,3])\n",
    "        #x = tf.reshape(x, [-1, self.timepoints, tf.cast(self.wavelengths * self.representations, tf.int32)])\n",
    "        return x\n",
    "    \n",
    "class Reshape11(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        x = tf.transpose(x, perm=[0,2,1])\n",
    "        #x = tf.reshape(x, [-1, self.timepoints, tf.cast(self.wavelengths * self.representations, tf.int32)])\n",
    "        return x\n",
    "\n",
    "class Reshape2(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x_pred, x_confidence):\n",
    "        x = tf.concat([x_pred, x_confidence], axis = -1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Reshape22(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x_pred, x_confidence):\n",
    "        x_pred = tf.expand_dims(x_pred, axis=-1)\n",
    "        x_confidence = tf.expand_dims(x_confidence, axis=-1)\n",
    "        x = tf.concat([x_pred, x_confidence], axis = -1)\n",
    "        return x\n",
    "    \n",
    "class reduce(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        mean = tf.reduce_sum(x,axis=-1)\n",
    "        mean = tf.expand_dims(mean, axis=-1)\n",
    "        return mean\n",
    "class reduce1(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        mean = tf.reduce_sum(x,axis=-1)\n",
    "        return mean\n",
    "    \n",
    "class tile(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x,mean):\n",
    "        x = tf.concat([x,mean],axis=-1)\n",
    "        return x\n",
    "    \n",
    "class tile2(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x,mean):\n",
    "        x = tf.concat([x,tf.expand_dims(mean,axis=-1)],axis=-2)\n",
    "        return x\n",
    "    \n",
    "class meanOfWavelengths(tf.keras.layers.Layer):\n",
    "    def __init__(self, concat=True,**kwargs):\n",
    "        self.concat=concat\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, x):\n",
    "        m = tf.expand_dims(tf.reduce_mean(x,axis=-1),axis=-1)\n",
    "        x = tf.concat([x,m],axis=-1)\n",
    "        return x if self.concat else m\n",
    "\n",
    "\n",
    "timepoints = 225\n",
    "representations = 4\n",
    "wavelengths = 283\n",
    "targetWavelengths = 283\n",
    "\n",
    "def cnnDepthwise():\n",
    "    inp = tf.keras.Input(shape=(timepoints, wavelengths, representations))\n",
    "    x = inp[:,:,:,1]\n",
    "    x = meanOfWavelengths()(x)\n",
    "    # timepoints (225) * wavelengths (284)\n",
    "    \n",
    "    #x = Reshape11()(x)\n",
    "    dim = timepoints\n",
    "    for i in range(3):\n",
    "        # depthwise1d filter -> one filter per channel (=wavelength), depth_multiplier tells us how many filters per channel\n",
    "        x = tf.keras.layers.DepthwiseConv1D(kernel_size=5,strides=1,padding='same', depth_multiplier=2,activation='relu')(x)\n",
    "        #x = tf.keras.layers.Conv1D(filters=284, kernel_size=(5), padding='valid')(x)\n",
    "        x = tf.keras.layers.AveragePooling1D(2)(x)\n",
    "        x = tf.keras.layers.Dense(284)(x)\n",
    "    \n",
    "    x = tf.keras.layers.DepthwiseConv1D(kernel_size=5,strides=1,padding='same', depth_multiplier=2,activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(283)(x)\n",
    "    x = Reshape11()(x)\n",
    "    x = tf.keras.layers.Dense(1000)(x)\n",
    "    x = tf.keras.layers.Dense(100)(x)\n",
    "    \n",
    "    x_pred = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    x_confidence = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    x = Reshape2()(x_pred, x_confidence)\n",
    "\n",
    "    model = tf.keras.Model(inp, x)\n",
    "    return model\n",
    "\n",
    "model = cnnDepthwise() \n",
    "#model = cnnM() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64,\n",
       " tf.float32,\n",
       " tf.float32,\n",
       " TensorShape([64, 225, 283, 4]),\n",
       " TensorShape([64, 283]),\n",
       " TensorShape([64, 283, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataset))\n",
    "out = model(batch[0])\n",
    "test_batch = next(iter(test_dataset))\n",
    "batch[0].dtype ,batch[1].dtype, out.dtype,batch[0].shape ,batch[1].shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, 0.9999999999998191)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_likelihood_maxScaling(y_trueMax, y_pred):\n",
    "    # stdDev_zScorePred = 1/n * sqrt((y_zScore - y_zScoreMean)^2) = 1/n *sqrt(sum( (y-mean)/std - (y_mean-mean)/std )^2) = 1/n * sqrt(sum( (y-y_mean)/std )^2 )) = 1/std * 1/n * sqrt(sum(y-y_mean)^2) = stdDev / std\n",
    "    # stdDev_zScorePred = stdDev_pred / std\n",
    "    # y_pred contains 1. y_zScore 2. log(stdDev_zScore)\n",
    "\n",
    "    y_true = y_trueMax * maxTrainLabels #std + mean   # y_zScore = (y - mean) / std -> y = y_zScore *std + mean\n",
    "\n",
    "    y_predMax = y_pred[:, :,0]\n",
    "    log_sigma = y_pred[:, :,1]  # Log of the standard deviation / we predict log(stdDev_zScore) = log(stdDev / std) = log(stdDev) - log(std) -> log(stdDev) = log(stdDev_zScore) + log(std)\n",
    "\n",
    "    y_pred0 = y_predMax *maxTrainLabels #* std + mean\n",
    "    sigma = tf.exp(log_sigma)*maxTrainLabels  # Exponentiate to get variance + scale back from zscore \n",
    "    logStdDev = tf.math.log(sigma*sigma)# + tf.math.log(max)\n",
    "\n",
    "    L_pred = -0.5*(tf.math.log(2*np.pi) + logStdDev + tf.square((y_true - y_pred0) / sigma))\n",
    "    L_ref = -0.5*(tf.math.log(2*np.pi) +  tf.math.log(stdLabels**4) + tf.square((y_true - meanLabels)/(stdLabels*stdLabels)))   # ( (y_true - mean)/std )^2 = y_trueZScore^2  (y_true = y_trueZScore * std + mean)\n",
    "    L_ideal = -0.5*(tf.math.log(2*np.pi) + tf.math.log((1e-5)**4)) * tf.ones_like(y_predMax)\n",
    "    #print(L_pred)\n",
    "    #print(L_ref)\n",
    "    #print(L_ideal)\n",
    "    #print(tf.reduce_sum(L_pred),tf.reduce_sum(L_ideal),tf.reduce_sum(L_ref))\n",
    "    L = (tf.reduce_sum(L_pred) -tf.reduce_sum(L_ref)) / (tf.reduce_sum(L_ideal) - tf.reduce_sum(L_ref))\n",
    "    \n",
    "    return L\n",
    "\n",
    "def log_likelihood_maxScaling_scipy(y_trueMax, y_pred):\n",
    "    y_true = y_trueMax * maxTrainLabels #std + mean   # y_zScore = (y - mean) / std -> y = y_zScore *std + mean\n",
    "\n",
    "    y_predMax = y_pred[:, :,0]\n",
    "    log_sigma = y_pred[:, :,1]  # Log of the standard deviation / we predict log(stdDev_zScore) = log(stdDev / std) = log(stdDev) - log(std) -> log(stdDev) = log(stdDev_zScore) + log(std)\n",
    "\n",
    "    y_pred0 = y_predMax *maxTrainLabels #* std + mean\n",
    "    sigma = tf.exp(log_sigma)*maxTrainLabels  # Exponentiate to get variance + scale back from zscore \n",
    "\n",
    "    GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred0, scale=sigma))\n",
    "    GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=(1e-10) * np.ones_like(y_true)))\n",
    "    GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=meanLabels * np.ones_like(y_true), scale=(stdLabels*stdLabels) * np.ones_like(y_true)))\n",
    "\n",
    "    submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n",
    "    #print(GLL_pred, GLL_true, GLL_mean)\n",
    "    \n",
    "    return submit_score\n",
    "\n",
    "log_likelihood_maxScaling(batch[1], out),log_likelihood_maxScaling_scipy(batch[1],out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([ 40.68333 , 162.26318 ,  35.736195, 164.84949 ,  29.588648,\n",
       "         31.77409 ,  39.459396,  87.99548 ,  33.062145, 146.09706 ,\n",
       "         56.535645,  31.32294 ,  36.347675,  29.141367, 132.4765  ,\n",
       "         29.61394 ,  89.67991 ,  39.12401 ,  35.87329 , 132.97298 ,\n",
       "         31.743832,  37.123276,  43.7431  ,  29.129421,  32.946198,\n",
       "        130.27525 ,  42.08177 ,  67.48109 ,  46.082497,  34.130802,\n",
       "        161.15823 ,  30.483656,  60.23376 ,  28.892202,  43.652443,\n",
       "        132.42764 ,  91.15231 ,  33.524563,  94.55391 ,  50.91206 ,\n",
       "         33.7087  ,  51.63279 ,  34.587044,  39.019962,  33.717842,\n",
       "         32.646435,  32.51447 ,  43.238064, 209.43915 ,  70.86312 ,\n",
       "         50.009995,  44.85477 ,  42.98866 ,  48.334755,  35.171127,\n",
       "         98.18271 ,  32.240875,  41.226566, 105.30651 , 177.93816 ,\n",
       "         32.292652,  37.920948,  38.664062,  36.87942 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1), dtype=float32, numpy=\n",
       " array([[0.23250966],\n",
       "        [0.74391955],\n",
       "        [0.18068469],\n",
       "        [0.7506303 ],\n",
       "        [0.07539631],\n",
       "        [0.12374088],\n",
       "        [0.22056323],\n",
       "        [0.50521535],\n",
       "        [0.14478642],\n",
       "        [0.6999782 ],\n",
       "        [0.35046595],\n",
       "        [0.115446  ],\n",
       "        [0.18811177],\n",
       "        [0.06092482],\n",
       "        [0.660549  ],\n",
       "        [0.07584774],\n",
       "        [0.51212424],\n",
       "        [0.21800654],\n",
       "        [0.1825123 ],\n",
       "        [0.66202605],\n",
       "        [0.12315061],\n",
       "        [0.19693582],\n",
       "        [0.259826  ],\n",
       "        [0.06050046],\n",
       "        [0.14305148],\n",
       "        [0.65378755],\n",
       "        [0.24579373],\n",
       "        [0.41166675],\n",
       "        [0.27808073],\n",
       "        [0.16022544],\n",
       "        [0.7407524 ],\n",
       "        [0.09813663],\n",
       "        [0.37235045],\n",
       "        [0.05113037],\n",
       "        [0.2587781 ],\n",
       "        [0.6603954 ],\n",
       "        [0.51826394],\n",
       "        [0.15169248],\n",
       "        [0.5316238 ],\n",
       "        [0.31409955],\n",
       "        [0.15433338],\n",
       "        [0.3171791 ],\n",
       "        [0.1663545 ],\n",
       "        [0.21682929],\n",
       "        [0.15375425],\n",
       "        [0.13838843],\n",
       "        [0.1334862 ],\n",
       "        [0.2558167 ],\n",
       "        [0.8560697 ],\n",
       "        [0.4286932 ],\n",
       "        [0.30783665],\n",
       "        [0.2691615 ],\n",
       "        [0.25364557],\n",
       "        [0.29525205],\n",
       "        [0.17388101],\n",
       "        [0.5455155 ],\n",
       "        [0.13157554],\n",
       "        [0.23808844],\n",
       "        [0.57162935],\n",
       "        [0.78346294],\n",
       "        [0.13263614],\n",
       "        [0.20554084],\n",
       "        [0.21328945],\n",
       "        [0.19404969]], dtype=float32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combined_loss_mse(y_trueScaled, y_pred):\n",
    "    y_predScaled = y_pred[:, :,0]\n",
    "    lossPred = tf.square(y_trueScaled - y_predScaled)#tf.math.abs(y_true_zScore-y_predZScore)\n",
    "\n",
    "    logConfidence = tf.math.exp(y_pred[:, :,1]) # logSigma = log(sigma / std)  we predict sigma NOT stdDev!!\n",
    "    largerThanT = tf.greater(logConfidence, tf.exp(20.0))\n",
    "    logConfidence = tf.where(largerThanT, y_pred[:,:,1] + tf.exp(20.0), logConfidence)    \n",
    "\n",
    "    loss_2 = tf.square(lossPred-(logConfidence))\n",
    "\n",
    "\n",
    "    combinedLoss = tf.reduce_sum(lossPred+loss_2*0.1, axis=-1)\n",
    "    #combinedLoss = tf.reduce_sum(lossMean, axis=-1)\n",
    "    return combinedLoss\n",
    "\n",
    "def mean_mae(y_trueScaled, y_pred):\n",
    "    y_predMean = tf.expand_dims(tf.reduce_mean(y_pred[:,:,0],axis=-1),axis=-1)\n",
    "    y_trueMean = tf.expand_dims(tf.reduce_mean(y_trueScaled,axis=-1),axis=-1)\n",
    "    return tf.abs(y_predMean-y_trueMean)\n",
    "\n",
    "#loss_mse(batch[1],out)\n",
    "combined_loss_mse(batch[1],out), mean_mae(batch[1],out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 62.2147 - mean_mae: 0.3169 - val_loss: 63.7196 - val_mean_mae: 0.3181\n",
      "Epoch 2/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 63.0551 - mean_mae: 0.3174 - val_loss: 63.2057 - val_mean_mae: 0.3150\n",
      "Epoch 3/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 62.7387 - mean_mae: 0.3134 - val_loss: 62.6828 - val_mean_mae: 0.3118\n",
      "Epoch 4/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 58.6279 - mean_mae: 0.2952 - val_loss: 62.1506 - val_mean_mae: 0.3085\n",
      "Epoch 5/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 62.8938 - mean_mae: 0.3123 - val_loss: 61.6027 - val_mean_mae: 0.3051\n",
      "Epoch 6/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 60.9547 - mean_mae: 0.3057 - val_loss: 61.0467 - val_mean_mae: 0.3016\n",
      "Epoch 7/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 60.6030 - mean_mae: 0.3006 - val_loss: 60.4830 - val_mean_mae: 0.2981\n",
      "Epoch 8/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 59.2586 - mean_mae: 0.2948 - val_loss: 59.9056 - val_mean_mae: 0.2944\n",
      "Epoch 9/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 59.8477 - mean_mae: 0.2959 - val_loss: 59.3168 - val_mean_mae: 0.2906\n",
      "Epoch 10/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 59.2507 - mean_mae: 0.2977 - val_loss: 58.7133 - val_mean_mae: 0.2866\n",
      "Epoch 11/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 56.0484 - mean_mae: 0.2773 - val_loss: 58.1014 - val_mean_mae: 0.2826\n",
      "Epoch 12/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 53.5271 - mean_mae: 0.2603 - val_loss: 57.4745 - val_mean_mae: 0.2784\n",
      "Epoch 13/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 56.0161 - mean_mae: 0.2757 - val_loss: 56.8304 - val_mean_mae: 0.2740\n",
      "Epoch 14/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 55.5302 - mean_mae: 0.2737 - val_loss: 56.1722 - val_mean_mae: 0.2695\n",
      "Epoch 15/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 52.7627 - mean_mae: 0.2541 - val_loss: 55.5147 - val_mean_mae: 0.2650\n",
      "Epoch 16/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 53.3399 - mean_mae: 0.2572 - val_loss: 54.8407 - val_mean_mae: 0.2604\n",
      "Epoch 17/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 55.6519 - mean_mae: 0.2678 - val_loss: 54.1397 - val_mean_mae: 0.2557\n",
      "Epoch 18/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 53.0466 - mean_mae: 0.2552 - val_loss: 53.4421 - val_mean_mae: 0.2510\n",
      "Epoch 19/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 52.0266 - mean_mae: 0.2449 - val_loss: 52.7431 - val_mean_mae: 0.2464\n",
      "Epoch 20/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 50.9724 - mean_mae: 0.2400 - val_loss: 52.0288 - val_mean_mae: 0.2417\n",
      "Epoch 21/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 48.3653 - mean_mae: 0.2274 - val_loss: 51.2844 - val_mean_mae: 0.2368\n",
      "Epoch 22/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 49.2638 - mean_mae: 0.2266 - val_loss: 50.5274 - val_mean_mae: 0.2319\n",
      "Epoch 23/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 48.8664 - mean_mae: 0.2236 - val_loss: 49.7786 - val_mean_mae: 0.2269\n",
      "Epoch 24/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 47.1838 - mean_mae: 0.2148 - val_loss: 49.0356 - val_mean_mae: 0.2222\n",
      "Epoch 25/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 46.7385 - mean_mae: 0.2134 - val_loss: 48.2811 - val_mean_mae: 0.2174\n",
      "Epoch 26/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 43.9357 - mean_mae: 0.1895 - val_loss: 47.5234 - val_mean_mae: 0.2128\n",
      "Epoch 27/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 45.0823 - mean_mae: 0.1962 - val_loss: 46.7514 - val_mean_mae: 0.2080\n",
      "Epoch 28/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 44.4726 - mean_mae: 0.1940 - val_loss: 45.9857 - val_mean_mae: 0.2033\n",
      "Epoch 29/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 44.2895 - mean_mae: 0.1957 - val_loss: 45.2244 - val_mean_mae: 0.1990\n",
      "Epoch 30/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 45.3737 - mean_mae: 0.1983 - val_loss: 44.4724 - val_mean_mae: 0.1950\n",
      "Epoch 31/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 42.6856 - mean_mae: 0.1834 - val_loss: 43.7430 - val_mean_mae: 0.1913\n",
      "Epoch 32/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 41.9685 - mean_mae: 0.1823 - val_loss: 43.0328 - val_mean_mae: 0.1879\n",
      "Epoch 33/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 43.0416 - mean_mae: 0.1929 - val_loss: 42.3301 - val_mean_mae: 0.1848\n",
      "Epoch 34/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 39.6919 - mean_mae: 0.1666 - val_loss: 41.6512 - val_mean_mae: 0.1818\n",
      "Epoch 35/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 39.9775 - mean_mae: 0.1737 - val_loss: 40.9806 - val_mean_mae: 0.1791\n",
      "Epoch 36/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 40.8832 - mean_mae: 0.1807 - val_loss: 40.3288 - val_mean_mae: 0.1767\n",
      "Epoch 37/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 39.2467 - mean_mae: 0.1728 - val_loss: 39.6904 - val_mean_mae: 0.1747\n",
      "Epoch 38/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 38.5401 - mean_mae: 0.1690 - val_loss: 39.0598 - val_mean_mae: 0.1730\n",
      "Epoch 39/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 39.1785 - mean_mae: 0.1748 - val_loss: 38.4506 - val_mean_mae: 0.1717\n",
      "Epoch 40/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 37.5619 - mean_mae: 0.1669 - val_loss: 37.8812 - val_mean_mae: 0.1708\n",
      "Epoch 41/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 36.1147 - mean_mae: 0.1609 - val_loss: 37.3520 - val_mean_mae: 0.1702\n",
      "Epoch 42/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 36.1912 - mean_mae: 0.1663 - val_loss: 36.8378 - val_mean_mae: 0.1698\n",
      "Epoch 43/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 35.8197 - mean_mae: 0.1615 - val_loss: 36.3330 - val_mean_mae: 0.1696\n",
      "Epoch 44/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 34.8644 - mean_mae: 0.1591 - val_loss: 35.8419 - val_mean_mae: 0.1699\n",
      "Epoch 45/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 33.9151 - mean_mae: 0.1571 - val_loss: 35.3903 - val_mean_mae: 0.1704\n",
      "Epoch 46/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 34.4593 - mean_mae: 0.1640 - val_loss: 34.9567 - val_mean_mae: 0.1711\n",
      "Epoch 47/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 34.2382 - mean_mae: 0.1645 - val_loss: 34.5354 - val_mean_mae: 0.1719\n",
      "Epoch 48/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 33.9800 - mean_mae: 0.1678 - val_loss: 34.1382 - val_mean_mae: 0.1726\n",
      "Epoch 49/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 33.0716 - mean_mae: 0.1638 - val_loss: 33.7736 - val_mean_mae: 0.1733\n",
      "Epoch 50/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 32.6051 - mean_mae: 0.1639 - val_loss: 33.4307 - val_mean_mae: 0.1739\n",
      "Epoch 51/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 32.9212 - mean_mae: 0.1694 - val_loss: 33.0885 - val_mean_mae: 0.1744\n",
      "Epoch 52/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 31.7898 - mean_mae: 0.1635 - val_loss: 32.7523 - val_mean_mae: 0.1750\n",
      "Epoch 53/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 31.6942 - mean_mae: 0.1671 - val_loss: 32.4160 - val_mean_mae: 0.1756\n",
      "Epoch 54/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 31.1780 - mean_mae: 0.1660 - val_loss: 32.0736 - val_mean_mae: 0.1763\n",
      "Epoch 55/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 31.4842 - mean_mae: 0.1714 - val_loss: 31.7341 - val_mean_mae: 0.1771\n",
      "Epoch 56/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 30.6453 - mean_mae: 0.1675 - val_loss: 31.4097 - val_mean_mae: 0.1776\n",
      "Epoch 57/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 31.0557 - mean_mae: 0.1756 - val_loss: 31.0908 - val_mean_mae: 0.1781\n",
      "Epoch 58/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 29.5497 - mean_mae: 0.1635 - val_loss: 30.7756 - val_mean_mae: 0.1784\n",
      "Epoch 59/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 29.6576 - mean_mae: 0.1687 - val_loss: 30.4610 - val_mean_mae: 0.1788\n",
      "Epoch 60/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 29.5572 - mean_mae: 0.1696 - val_loss: 30.1451 - val_mean_mae: 0.1791\n",
      "Epoch 61/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 29.3986 - mean_mae: 0.1727 - val_loss: 29.8265 - val_mean_mae: 0.1796\n",
      "Epoch 62/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 28.3368 - mean_mae: 0.1672 - val_loss: 29.5140 - val_mean_mae: 0.1799\n",
      "Epoch 63/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 28.3312 - mean_mae: 0.1712 - val_loss: 29.1998 - val_mean_mae: 0.1802\n",
      "Epoch 64/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 28.7979 - mean_mae: 0.1771 - val_loss: 28.8877 - val_mean_mae: 0.1805\n",
      "Epoch 65/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 27.6751 - mean_mae: 0.1707 - val_loss: 28.5791 - val_mean_mae: 0.1804\n",
      "Epoch 66/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 27.5707 - mean_mae: 0.1707 - val_loss: 28.2692 - val_mean_mae: 0.1804\n",
      "Epoch 67/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 27.8589 - mean_mae: 0.1766 - val_loss: 27.9573 - val_mean_mae: 0.1802\n",
      "Epoch 68/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 27.4930 - mean_mae: 0.1757 - val_loss: 27.6511 - val_mean_mae: 0.1798\n",
      "Epoch 69/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 26.9486 - mean_mae: 0.1744 - val_loss: 27.3478 - val_mean_mae: 0.1792\n",
      "Epoch 70/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 26.4785 - mean_mae: 0.1711 - val_loss: 27.0408 - val_mean_mae: 0.1787\n",
      "Epoch 71/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 26.2814 - mean_mae: 0.1728 - val_loss: 26.7269 - val_mean_mae: 0.1784\n",
      "Epoch 72/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 25.9803 - mean_mae: 0.1718 - val_loss: 26.4059 - val_mean_mae: 0.1782\n",
      "Epoch 73/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 25.3586 - mean_mae: 0.1702 - val_loss: 26.0971 - val_mean_mae: 0.1776\n",
      "Epoch 74/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 24.6801 - mean_mae: 0.1660 - val_loss: 25.7749 - val_mean_mae: 0.1772\n",
      "Epoch 75/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 25.1613 - mean_mae: 0.1706 - val_loss: 25.4376 - val_mean_mae: 0.1772\n",
      "Epoch 76/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 24.2458 - mean_mae: 0.1653 - val_loss: 25.0998 - val_mean_mae: 0.1772\n",
      "Epoch 77/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 24.1900 - mean_mae: 0.1686 - val_loss: 24.7621 - val_mean_mae: 0.1772\n",
      "Epoch 78/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 23.8398 - mean_mae: 0.1684 - val_loss: 24.4177 - val_mean_mae: 0.1773\n",
      "Epoch 79/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 23.2507 - mean_mae: 0.1663 - val_loss: 24.0754 - val_mean_mae: 0.1770\n",
      "Epoch 80/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 22.8819 - mean_mae: 0.1671 - val_loss: 23.7317 - val_mean_mae: 0.1766\n",
      "Epoch 81/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 22.8459 - mean_mae: 0.1696 - val_loss: 23.3881 - val_mean_mae: 0.1760\n",
      "Epoch 82/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 22.3164 - mean_mae: 0.1674 - val_loss: 23.0452 - val_mean_mae: 0.1751\n",
      "Epoch 83/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 22.0313 - mean_mae: 0.1663 - val_loss: 22.6966 - val_mean_mae: 0.1745\n",
      "Epoch 84/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 21.4424 - mean_mae: 0.1636 - val_loss: 22.3404 - val_mean_mae: 0.1741\n",
      "Epoch 85/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 21.1728 - mean_mae: 0.1628 - val_loss: 21.9807 - val_mean_mae: 0.1739\n",
      "Epoch 86/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 20.8796 - mean_mae: 0.1637 - val_loss: 21.6221 - val_mean_mae: 0.1735\n",
      "Epoch 87/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 20.3600 - mean_mae: 0.1628 - val_loss: 21.2616 - val_mean_mae: 0.1733\n",
      "Epoch 88/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 20.8720 - mean_mae: 0.1702 - val_loss: 20.9025 - val_mean_mae: 0.1729\n",
      "Epoch 89/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 19.7341 - mean_mae: 0.1628 - val_loss: 20.5485 - val_mean_mae: 0.1717\n",
      "Epoch 90/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 20.1564 - mean_mae: 0.1682 - val_loss: 20.1924 - val_mean_mae: 0.1708\n",
      "Epoch 91/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 19.0747 - mean_mae: 0.1613 - val_loss: 19.8420 - val_mean_mae: 0.1693\n",
      "Epoch 92/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 19.1107 - mean_mae: 0.1608 - val_loss: 19.4901 - val_mean_mae: 0.1682\n",
      "Epoch 93/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 18.4278 - mean_mae: 0.1570 - val_loss: 19.1420 - val_mean_mae: 0.1669\n",
      "Epoch 94/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 17.9920 - mean_mae: 0.1577 - val_loss: 18.7968 - val_mean_mae: 0.1655\n",
      "Epoch 95/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 17.7507 - mean_mae: 0.1545 - val_loss: 18.4611 - val_mean_mae: 0.1638\n",
      "Epoch 96/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 18.0206 - mean_mae: 0.1593 - val_loss: 18.1204 - val_mean_mae: 0.1625\n",
      "Epoch 97/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 17.3349 - mean_mae: 0.1536 - val_loss: 17.7879 - val_mean_mae: 0.1610\n",
      "Epoch 98/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 17.6226 - mean_mae: 0.1586 - val_loss: 17.4507 - val_mean_mae: 0.1600\n",
      "Epoch 99/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 16.9665 - mean_mae: 0.1537 - val_loss: 17.1188 - val_mean_mae: 0.1590\n",
      "Epoch 100/800\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 16.5424 - mean_mae: 0.1516\n",
      "Epoch 100: saving model to C:/Users/uic33116/Documents/documents/ariel-data-challenge-2024/training_full_model/model-100.weights.h5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 16.4323 - mean_mae: 0.1510 - val_loss: 16.7880 - val_mean_mae: 0.1580\n",
      "Epoch 101/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 15.8202 - mean_mae: 0.1469 - val_loss: 16.4642 - val_mean_mae: 0.1571\n",
      "Epoch 102/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 15.3863 - mean_mae: 0.1467 - val_loss: 16.1590 - val_mean_mae: 0.1556\n",
      "Epoch 103/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 15.7472 - mean_mae: 0.1493 - val_loss: 15.8616 - val_mean_mae: 0.1543\n",
      "Epoch 104/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 14.9097 - mean_mae: 0.1452 - val_loss: 15.5754 - val_mean_mae: 0.1529\n",
      "Epoch 105/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 14.9102 - mean_mae: 0.1454 - val_loss: 15.2783 - val_mean_mae: 0.1522\n",
      "Epoch 106/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 14.0267 - mean_mae: 0.1388 - val_loss: 14.9887 - val_mean_mae: 0.1515\n",
      "Epoch 107/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 14.2167 - mean_mae: 0.1421 - val_loss: 14.7200 - val_mean_mae: 0.1500\n",
      "Epoch 108/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 13.6970 - mean_mae: 0.1401 - val_loss: 14.4619 - val_mean_mae: 0.1482\n",
      "Epoch 109/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 13.5242 - mean_mae: 0.1391 - val_loss: 14.1976 - val_mean_mae: 0.1473\n",
      "Epoch 110/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 13.7316 - mean_mae: 0.1410 - val_loss: 13.9361 - val_mean_mae: 0.1471\n",
      "Epoch 111/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 13.4836 - mean_mae: 0.1418 - val_loss: 13.6892 - val_mean_mae: 0.1466\n",
      "Epoch 112/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 12.6433 - mean_mae: 0.1331 - val_loss: 13.4529 - val_mean_mae: 0.1456\n",
      "Epoch 113/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 13.1079 - mean_mae: 0.1407 - val_loss: 13.2271 - val_mean_mae: 0.1449\n",
      "Epoch 114/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 12.1868 - mean_mae: 0.1348 - val_loss: 13.0069 - val_mean_mae: 0.1432\n",
      "Epoch 115/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 12.1297 - mean_mae: 0.1319 - val_loss: 12.7996 - val_mean_mae: 0.1415\n",
      "Epoch 116/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 12.1289 - mean_mae: 0.1314 - val_loss: 12.5972 - val_mean_mae: 0.1407\n",
      "Epoch 117/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 11.9012 - mean_mae: 0.1301 - val_loss: 12.4046 - val_mean_mae: 0.1395\n",
      "Epoch 118/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 11.4541 - mean_mae: 0.1286 - val_loss: 12.2175 - val_mean_mae: 0.1387\n",
      "Epoch 119/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 11.7817 - mean_mae: 0.1335 - val_loss: 12.0349 - val_mean_mae: 0.1381\n",
      "Epoch 120/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 11.3192 - mean_mae: 0.1303 - val_loss: 11.8587 - val_mean_mae: 0.1374\n",
      "Epoch 121/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 11.3283 - mean_mae: 0.1291 - val_loss: 11.6934 - val_mean_mae: 0.1366\n",
      "Epoch 122/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.5480 - mean_mae: 0.1228 - val_loss: 11.5367 - val_mean_mae: 0.1356\n",
      "Epoch 123/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.4297 - mean_mae: 0.1229 - val_loss: 11.3919 - val_mean_mae: 0.1344\n",
      "Epoch 124/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.8853 - mean_mae: 0.1268 - val_loss: 11.2581 - val_mean_mae: 0.1333\n",
      "Epoch 125/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.6052 - mean_mae: 0.1258 - val_loss: 11.1171 - val_mean_mae: 0.1329\n",
      "Epoch 126/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.3994 - mean_mae: 0.1238 - val_loss: 10.9752 - val_mean_mae: 0.1325\n",
      "Epoch 127/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.2319 - mean_mae: 0.1238 - val_loss: 10.8237 - val_mean_mae: 0.1331\n",
      "Epoch 128/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 10.3461 - mean_mae: 0.1280 - val_loss: 10.6914 - val_mean_mae: 0.1338\n",
      "Epoch 129/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.7486 - mean_mae: 0.1199 - val_loss: 10.5644 - val_mean_mae: 0.1331\n",
      "Epoch 130/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.6635 - mean_mae: 0.1212 - val_loss: 10.4440 - val_mean_mae: 0.1325\n",
      "Epoch 131/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.9207 - mean_mae: 0.1271 - val_loss: 10.3285 - val_mean_mae: 0.1325\n",
      "Epoch 132/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.2892 - mean_mae: 0.1200 - val_loss: 10.2298 - val_mean_mae: 0.1331\n",
      "Epoch 133/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.3516 - mean_mae: 0.1231 - val_loss: 10.1151 - val_mean_mae: 0.1323\n",
      "Epoch 134/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 9.3752 - mean_mae: 0.1212 - val_loss: 10.0120 - val_mean_mae: 0.1320\n",
      "Epoch 135/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.2100 - mean_mae: 0.1206 - val_loss: 9.9092 - val_mean_mae: 0.1315\n",
      "Epoch 136/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.0250 - mean_mae: 0.1186 - val_loss: 9.8081 - val_mean_mae: 0.1297\n",
      "Epoch 137/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 9.2476 - mean_mae: 0.1210 - val_loss: 9.7150 - val_mean_mae: 0.1297\n",
      "Epoch 138/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 8.8720 - mean_mae: 0.1195 - val_loss: 9.6275 - val_mean_mae: 0.1296\n",
      "Epoch 139/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 8.2879 - mean_mae: 0.1136 - val_loss: 9.5446 - val_mean_mae: 0.1294\n",
      "Epoch 140/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.9521 - mean_mae: 0.1201 - val_loss: 9.4652 - val_mean_mae: 0.1295\n",
      "Epoch 141/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 9.0923 - mean_mae: 0.1217 - val_loss: 9.3837 - val_mean_mae: 0.1285\n",
      "Epoch 142/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.7465 - mean_mae: 0.1182 - val_loss: 9.3168 - val_mean_mae: 0.1275\n",
      "Epoch 143/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.8008 - mean_mae: 0.1195 - val_loss: 9.2481 - val_mean_mae: 0.1272\n",
      "Epoch 144/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.0279 - mean_mae: 0.1130 - val_loss: 9.1946 - val_mean_mae: 0.1266\n",
      "Epoch 145/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.1879 - mean_mae: 0.1131 - val_loss: 9.1466 - val_mean_mae: 0.1261\n",
      "Epoch 146/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.9320 - mean_mae: 0.1215 - val_loss: 9.0449 - val_mean_mae: 0.1271\n",
      "Epoch 147/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 8.6636 - mean_mae: 0.1226 - val_loss: 8.9820 - val_mean_mae: 0.1270\n",
      "Epoch 148/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 8.2001 - mean_mae: 0.1172 - val_loss: 8.9099 - val_mean_mae: 0.1276\n",
      "Epoch 149/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 8.1696 - mean_mae: 0.1189 - val_loss: 8.8482 - val_mean_mae: 0.1279\n",
      "Epoch 150/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 8.5203 - mean_mae: 0.1231 - val_loss: 8.7890 - val_mean_mae: 0.1271\n",
      "Epoch 151/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 8.0707 - mean_mae: 0.1189 - val_loss: 8.7303 - val_mean_mae: 0.1271\n",
      "Epoch 152/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 8.2626 - mean_mae: 0.1199 - val_loss: 8.6754 - val_mean_mae: 0.1276\n",
      "Epoch 153/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.9345 - mean_mae: 0.1192 - val_loss: 8.6238 - val_mean_mae: 0.1276\n",
      "Epoch 154/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.4139 - mean_mae: 0.1109 - val_loss: 8.5689 - val_mean_mae: 0.1272\n",
      "Epoch 155/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.9186 - mean_mae: 0.1188 - val_loss: 8.5160 - val_mean_mae: 0.1264\n",
      "Epoch 156/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 8.0304 - mean_mae: 0.1202 - val_loss: 8.4671 - val_mean_mae: 0.1263\n",
      "Epoch 157/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 7.5548 - mean_mae: 0.1154 - val_loss: 8.4173 - val_mean_mae: 0.1255\n",
      "Epoch 158/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 7.4093 - mean_mae: 0.1124 - val_loss: 8.3769 - val_mean_mae: 0.1247\n",
      "Epoch 159/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.7457 - mean_mae: 0.1174 - val_loss: 8.3295 - val_mean_mae: 0.1246\n",
      "Epoch 160/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.2466 - mean_mae: 0.1119 - val_loss: 8.2845 - val_mean_mae: 0.1244\n",
      "Epoch 161/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.5506 - mean_mae: 0.1164 - val_loss: 8.2434 - val_mean_mae: 0.1242\n",
      "Epoch 162/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.8064 - mean_mae: 0.1156 - val_loss: 8.2082 - val_mean_mae: 0.1239\n",
      "Epoch 163/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.7710 - mean_mae: 0.1191 - val_loss: 8.1574 - val_mean_mae: 0.1245\n",
      "Epoch 164/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.7033 - mean_mae: 0.1174 - val_loss: 8.1182 - val_mean_mae: 0.1249\n",
      "Epoch 165/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.6007 - mean_mae: 0.1177 - val_loss: 8.0859 - val_mean_mae: 0.1253\n",
      "Epoch 166/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.1247 - mean_mae: 0.1113 - val_loss: 8.0429 - val_mean_mae: 0.1243\n",
      "Epoch 167/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.2887 - mean_mae: 0.1135 - val_loss: 8.0165 - val_mean_mae: 0.1233\n",
      "Epoch 168/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.2275 - mean_mae: 0.1170 - val_loss: 7.9823 - val_mean_mae: 0.1230\n",
      "Epoch 169/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.4928 - mean_mae: 0.1159 - val_loss: 7.9660 - val_mean_mae: 0.1255\n",
      "Epoch 170/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.2443 - mean_mae: 0.1166 - val_loss: 7.9543 - val_mean_mae: 0.1260\n",
      "Epoch 171/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 7.1079 - mean_mae: 0.1146 - val_loss: 7.8864 - val_mean_mae: 0.1244\n",
      "Epoch 172/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.9273 - mean_mae: 0.1132 - val_loss: 7.8454 - val_mean_mae: 0.1227\n",
      "Epoch 173/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.9710 - mean_mae: 0.1132 - val_loss: 7.8953 - val_mean_mae: 0.1207\n",
      "Epoch 174/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.0456 - mean_mae: 0.1110 - val_loss: 7.8662 - val_mean_mae: 0.1206\n",
      "Epoch 175/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.8664 - mean_mae: 0.1198 - val_loss: 7.7732 - val_mean_mae: 0.1218\n",
      "Epoch 176/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.3438 - mean_mae: 0.1173 - val_loss: 7.7359 - val_mean_mae: 0.1225\n",
      "Epoch 177/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.9705 - mean_mae: 0.1136 - val_loss: 7.7406 - val_mean_mae: 0.1244\n",
      "Epoch 178/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.9367 - mean_mae: 0.1136 - val_loss: 7.7050 - val_mean_mae: 0.1239\n",
      "Epoch 179/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.7285 - mean_mae: 0.1107 - val_loss: 7.6587 - val_mean_mae: 0.1224\n",
      "Epoch 180/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.0700 - mean_mae: 0.1129 - val_loss: 7.6331 - val_mean_mae: 0.1221\n",
      "Epoch 181/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.7242 - mean_mae: 0.1101 - val_loss: 7.6238 - val_mean_mae: 0.1209\n",
      "Epoch 182/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.8281 - mean_mae: 0.1119 - val_loss: 7.6059 - val_mean_mae: 0.1207\n",
      "Epoch 183/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.2852 - mean_mae: 0.1162 - val_loss: 7.5672 - val_mean_mae: 0.1213\n",
      "Epoch 184/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.6698 - mean_mae: 0.1109 - val_loss: 7.5517 - val_mean_mae: 0.1225\n",
      "Epoch 185/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.8281 - mean_mae: 0.1129 - val_loss: 7.5405 - val_mean_mae: 0.1229\n",
      "Epoch 186/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 7.1954 - mean_mae: 0.1173 - val_loss: 7.5081 - val_mean_mae: 0.1222\n",
      "Epoch 187/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.1170 - mean_mae: 0.1160 - val_loss: 7.4820 - val_mean_mae: 0.1213\n",
      "Epoch 188/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.7164 - mean_mae: 0.1117 - val_loss: 7.4780 - val_mean_mae: 0.1203\n",
      "Epoch 189/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.1213 - mean_mae: 0.1148 - val_loss: 7.4545 - val_mean_mae: 0.1204\n",
      "Epoch 190/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4141 - mean_mae: 0.1096 - val_loss: 7.4265 - val_mean_mae: 0.1210\n",
      "Epoch 191/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.0510 - mean_mae: 0.1154 - val_loss: 7.4327 - val_mean_mae: 0.1225\n",
      "Epoch 192/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5492 - mean_mae: 0.1122 - val_loss: 7.3955 - val_mean_mae: 0.1217\n",
      "Epoch 193/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4151 - mean_mae: 0.1086 - val_loss: 7.3730 - val_mean_mae: 0.1203\n",
      "Epoch 194/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4545 - mean_mae: 0.1099 - val_loss: 7.3600 - val_mean_mae: 0.1199\n",
      "Epoch 195/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4089 - mean_mae: 0.1097 - val_loss: 7.3456 - val_mean_mae: 0.1198\n",
      "Epoch 196/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - loss: 6.0056 - mean_mae: 0.1063 - val_loss: 7.3329 - val_mean_mae: 0.1215\n",
      "Epoch 197/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.8111 - mean_mae: 0.1147 - val_loss: 7.4672 - val_mean_mae: 0.1244\n",
      "Epoch 198/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.6106 - mean_mae: 0.1135 - val_loss: 7.3904 - val_mean_mae: 0.1232\n",
      "Epoch 199/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 6.3378 - mean_mae: 0.1106 - val_loss: 7.2830 - val_mean_mae: 0.1195\n",
      "Epoch 200/800\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 5.9978 - mean_mae: 0.1057\n",
      "Epoch 200: saving model to C:/Users/uic33116/Documents/documents/ariel-data-challenge-2024/training_full_model/model-200.weights.h5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2108 - mean_mae: 0.1073 - val_loss: 7.3753 - val_mean_mae: 0.1182\n",
      "Epoch 201/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.8498 - mean_mae: 0.1147 - val_loss: 7.3119 - val_mean_mae: 0.1185\n",
      "Epoch 202/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5347 - mean_mae: 0.1098 - val_loss: 7.2477 - val_mean_mae: 0.1193\n",
      "Epoch 203/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5340 - mean_mae: 0.1103 - val_loss: 7.2256 - val_mean_mae: 0.1199\n",
      "Epoch 204/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4480 - mean_mae: 0.1125 - val_loss: 7.2130 - val_mean_mae: 0.1199\n",
      "Epoch 205/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.3885 - mean_mae: 0.1090 - val_loss: 7.2355 - val_mean_mae: 0.1188\n",
      "Epoch 206/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5553 - mean_mae: 0.1089 - val_loss: 7.2245 - val_mean_mae: 0.1187\n",
      "Epoch 207/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 7.0258 - mean_mae: 0.1151 - val_loss: 7.2112 - val_mean_mae: 0.1188\n",
      "Epoch 208/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.1290 - mean_mae: 0.1067 - val_loss: 7.1701 - val_mean_mae: 0.1200\n",
      "Epoch 209/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.7510 - mean_mae: 0.1122 - val_loss: 7.2089 - val_mean_mae: 0.1218\n",
      "Epoch 210/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.7799 - mean_mae: 0.1171 - val_loss: 7.1849 - val_mean_mae: 0.1215\n",
      "Epoch 211/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4774 - mean_mae: 0.1142 - val_loss: 7.1383 - val_mean_mae: 0.1199\n",
      "Epoch 212/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.9837 - mean_mae: 0.1166 - val_loss: 7.1305 - val_mean_mae: 0.1193\n",
      "Epoch 213/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5173 - mean_mae: 0.1106 - val_loss: 7.1252 - val_mean_mae: 0.1204\n",
      "Epoch 214/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.6920 - mean_mae: 0.1154 - val_loss: 7.1488 - val_mean_mae: 0.1213\n",
      "Epoch 215/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2295 - mean_mae: 0.1093 - val_loss: 7.1054 - val_mean_mae: 0.1203\n",
      "Epoch 216/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2857 - mean_mae: 0.1096 - val_loss: 7.1251 - val_mean_mae: 0.1184\n",
      "Epoch 217/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.0765 - mean_mae: 0.1060 - val_loss: 7.0877 - val_mean_mae: 0.1190\n",
      "Epoch 218/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.1614 - mean_mae: 0.1085 - val_loss: 7.0822 - val_mean_mae: 0.1203\n",
      "Epoch 219/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5647 - mean_mae: 0.1123 - val_loss: 7.1272 - val_mean_mae: 0.1215\n",
      "Epoch 220/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.6638 - mean_mae: 0.1158 - val_loss: 7.0548 - val_mean_mae: 0.1193\n",
      "Epoch 221/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.0411 - mean_mae: 0.1074 - val_loss: 7.1178 - val_mean_mae: 0.1178\n",
      "Epoch 222/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.1083 - mean_mae: 0.1074 - val_loss: 7.0827 - val_mean_mae: 0.1180\n",
      "Epoch 223/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2802 - mean_mae: 0.1098 - val_loss: 7.0456 - val_mean_mae: 0.1185\n",
      "Epoch 224/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4180 - mean_mae: 0.1119 - val_loss: 7.0243 - val_mean_mae: 0.1194\n",
      "Epoch 225/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4896 - mean_mae: 0.1125 - val_loss: 7.0178 - val_mean_mae: 0.1195\n",
      "Epoch 226/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5554 - mean_mae: 0.1134 - val_loss: 7.0085 - val_mean_mae: 0.1190\n",
      "Epoch 227/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.0999 - mean_mae: 0.1075 - val_loss: 7.0038 - val_mean_mae: 0.1187\n",
      "Epoch 228/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.1718 - mean_mae: 0.1085 - val_loss: 7.0001 - val_mean_mae: 0.1185\n",
      "Epoch 229/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.3164 - mean_mae: 0.1097 - val_loss: 6.9977 - val_mean_mae: 0.1184\n",
      "Epoch 230/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.1940 - mean_mae: 0.1092 - val_loss: 6.9818 - val_mean_mae: 0.1188\n",
      "Epoch 231/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.3540 - mean_mae: 0.1122 - val_loss: 6.9918 - val_mean_mae: 0.1200\n",
      "Epoch 232/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5669 - mean_mae: 0.1145 - val_loss: 7.0126 - val_mean_mae: 0.1206\n",
      "Epoch 233/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.3262 - mean_mae: 0.1126 - val_loss: 6.9658 - val_mean_mae: 0.1195\n",
      "Epoch 234/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2529 - mean_mae: 0.1089 - val_loss: 6.9602 - val_mean_mae: 0.1186\n",
      "Epoch 235/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.0198 - mean_mae: 0.1077 - val_loss: 6.9833 - val_mean_mae: 0.1179\n",
      "Epoch 236/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.3858 - mean_mae: 0.1111 - val_loss: 6.9772 - val_mean_mae: 0.1179\n",
      "Epoch 237/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2750 - mean_mae: 0.1095 - val_loss: 6.9688 - val_mean_mae: 0.1180\n",
      "Epoch 238/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5710 - mean_mae: 0.1134 - val_loss: 6.9380 - val_mean_mae: 0.1190\n",
      "Epoch 239/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.0090 - mean_mae: 0.1067 - val_loss: 6.9332 - val_mean_mae: 0.1192\n",
      "Epoch 240/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 6.2510 - mean_mae: 0.1102 - val_loss: 6.9613 - val_mean_mae: 0.1179\n",
      "Epoch 241/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 6.1330 - mean_mae: 0.1090 - val_loss: 6.9849 - val_mean_mae: 0.1176\n",
      "Epoch 242/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 6.2182 - mean_mae: 0.1089 - val_loss: 6.9327 - val_mean_mae: 0.1183\n",
      "Epoch 243/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - loss: 6.5058 - mean_mae: 0.1145 - val_loss: 6.9179 - val_mean_mae: 0.1187\n",
      "Epoch 244/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 6.8074 - mean_mae: 0.1170 - val_loss: 6.9244 - val_mean_mae: 0.1183\n",
      "Epoch 245/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - loss: 5.9902 - mean_mae: 0.1076 - val_loss: 6.9082 - val_mean_mae: 0.1187\n",
      "Epoch 246/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 5.8955 - mean_mae: 0.1069 - val_loss: 6.9174 - val_mean_mae: 0.1200\n",
      "Epoch 247/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.1120 - mean_mae: 0.1109 - val_loss: 6.9987 - val_mean_mae: 0.1215\n",
      "Epoch 248/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.5898 - mean_mae: 0.1160 - val_loss: 6.9244 - val_mean_mae: 0.1202\n",
      "Epoch 249/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.0098 - mean_mae: 0.1087 - val_loss: 6.8903 - val_mean_mae: 0.1183\n",
      "Epoch 250/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.8236 - mean_mae: 0.1162 - val_loss: 6.9346 - val_mean_mae: 0.1175\n",
      "Epoch 251/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 5.9930 - mean_mae: 0.1064 - val_loss: 6.9226 - val_mean_mae: 0.1175\n",
      "Epoch 252/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.4341 - mean_mae: 0.1124 - val_loss: 6.8733 - val_mean_mae: 0.1186\n",
      "Epoch 253/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.6080 - mean_mae: 0.1132 - val_loss: 6.8770 - val_mean_mae: 0.1195\n",
      "Epoch 254/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 6.2801 - mean_mae: 0.1112 - val_loss: 6.8646 - val_mean_mae: 0.1186\n",
      "Epoch 255/800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.7890 - mean_mae: 0.1075"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m cnnDepthwise() \n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mcombined_loss_mse            \n\u001b[0;32m     15\u001b[0m               \u001b[38;5;66;03m#,metrics=[log_likelihood_maxScaling]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m               ,metrics\u001b[38;5;241m=\u001b[39m[mean_mae]\n\u001b[0;32m     17\u001b[0m               , optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[1;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_dataset, \n\u001b[0;32m     20\u001b[0m                     \u001b[38;5;66;03m#batch[0],batch[1], #verbose=2,\u001b[39;00m\n\u001b[0;32m     21\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[0;32m     22\u001b[0m                     \u001b[38;5;66;03m#validation_data=(test_batch[0],test_batch[1]),\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     24\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_callback]\n\u001b[0;32m     25\u001b[0m                     \u001b[38;5;66;03m#callbacks=[lr_callback]\u001b[39;00m\n\u001b[0;32m     26\u001b[0m                     )\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:345\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    336\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    337\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    344\u001b[0m     )\n\u001b[1;32m--> 345\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    346\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    347\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    348\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    349\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m    350\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    351\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    352\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m )\n\u001b[0;32m    355\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    357\u001b[0m }\n\u001b[0;32m    358\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:433\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    432\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 433\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    434\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    435\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m   )\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\uic33116\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"C:/Users/uic33116/Documents/documents/ariel-data-challenge-2024/training_full_model/model-{epoch:02d}.weights.h5\",\n",
    "    save_weights_only=True,  # Set to False if you want to save the entire model\n",
    "    save_freq=100 * 5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model = cnnDepthwise() \n",
    "model.compile(loss=combined_loss_mse            \n",
    "              #,metrics=[log_likelihood_maxScaling]\n",
    "              ,metrics=[mean_mae]\n",
    "              , optimizer=optimizer)\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    #batch[0],batch[1], #verbose=2,\n",
    "                    validation_data=test_dataset,\n",
    "                    #validation_data=(test_batch[0],test_batch[1]),\n",
    "                    epochs=800, batch_size=batch_size,\n",
    "                    callbacks=[checkpoint_callback]\n",
    "                    #callbacks=[lr_callback]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('originalData_fullM_866_epochs_blowup59_63.keras')\n",
    "# Save weights\n",
    "model.save_weights('800_fullModel_linearMean0078_0017_fullLoss_1_3.weights.h5')\n",
    "\n",
    "# Load weights\n",
    "#loaded_weights = model.load_weights('170_epochs_accLoss_reluActivation_23_23.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('120_epochs_accLoss31_30.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'history' is your model's training history\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "#plt.plot(epochs, test_loss, 'r', label='Test loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict(normData)\n",
    "outputs = model.predict(batch[0])\n",
    "pred = outputs[:,:,:]\n",
    "pred[0:10:,0:2,0]*maxLabels, batch[1][0:10:,0:2]*maxLabels ,np.exp(pred[0:10:,0:2,1])*maxLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(outputs[:,:,0],axis=-1), np.mean(batch[1],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.predict(test_batch[0])\n",
    "print('overall',(log_likelihood_maxScaling(test_batch[1],outputs)))\n",
    "#for i in range(batch_size):\n",
    "#    print(f'batch {i}',(log_likelihood_maxScaling(batch[1][i,:],outputs[i:i+1,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(4):#[2,6,10,20,100]:\n",
    "    fig.add_trace(go.Scatter(y=batch[0][i,:,0,0],mode='markers',name=f'f_{i}',marker=dict(size=3)))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(10): #range(12):# \n",
    "    fig.add_trace(go.Scatter(y=batch[1][i,:],mode='markers',name=f'gt_{i}',marker=dict(size=3)))\n",
    "    fig.add_trace(go.Scatter(y=pred[i,:,0],mode='markers',name=f'pred_{i}',marker=dict(size=3)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10): #range(12):#\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=batch[1][i,:],mode='markers',name=f'gt_{i}',marker=dict(size=3)))\n",
    "    fig.add_trace(go.Scatter(y=pred[i,:,0],mode='markers',name=f'pred_{i}',marker=dict(size=3)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
