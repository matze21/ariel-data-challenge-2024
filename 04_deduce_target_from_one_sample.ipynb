{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversion_helpers import *\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = \"\"  \n",
    "train_adc_info = pd.read_csv(os.path.join(path_folder, 'train_adc_info.csv'))\n",
    "train_adc_info = train_adc_info.set_index('planet_id')\n",
    "axis_info = pd.read_parquet(os.path.join(path_folder,'axis_info.parquet'))\n",
    "\n",
    "DO_MASK = True  # filter out non responsive pixels\n",
    "DO_THE_NL_CORR = True # most time consuming step, you can choose to ignore it for rapid prototyping, nonlinear correction due to artefacts when reading pixels\n",
    "DO_DARK = True  # dark current is accumulating over time in the pixels, need to compensate that (seems like integration artefact)\n",
    "DO_FLAT = True  # pixel to pixel variation correction (e.g. how pixels respond differently when illuminated uniformly)\n",
    "TIME_BINNING = False  #do a time binning on choosen frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_id = 612015401\n",
    "AIRS_cds_binned, FGS1_cds_binned,AIRS_cds_original, FGS1_cds_original = calibrateData(planet_id,train_adc_info,axis_info,DO_MASK,DO_THE_NL_CORR,DO_DARK,DO_FLAT,TIME_BINNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.loc[labels.planet_id == planet_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AIRS_cds_binned.sum(axis=(2,3))\n",
    "print(b.shape)\n",
    "plt.plot(b[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = AIRS_cds_original.sum(axis=(2,3))\n",
    "print(b.shape)\n",
    "plt.plot(b[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRS_cds_binned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization per frame: -> bad idea, wavelengths in one frame get comparable, but not super critical I guess, no strong impact there\n",
    "mean_p_frame = np.mean(AIRS_cds_binned, axis=(2,3), keepdims=True)\n",
    "std_p_frame = np.std(AIRS_cds_binned, axis=(2,3), keepdims=True)\n",
    "min_p_frame = np.min(AIRS_cds_binned, axis=(2,3), keepdims=True)\n",
    "max_p_frame = np.max(AIRS_cds_binned, axis=(2,3), keepdims=True)\n",
    "\n",
    "zScoreAIRS = (AIRS_cds_binned - mean_p_frame) / std_p_frame # gets rid of overall trend -> frames get uncomparable between each other\n",
    "zScoreAIRS = (AIRS_cds_binned - min_p_frame) / (max_p_frame - min_p_frame) # frames get uncomparable between each other\n",
    "b = zScoreAIRS.sum(axis=(2,3))\n",
    "print(b.shape)\n",
    "plt.plot(b[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization per wavelength: seems like the overall trend is also gone, individual wavelength is also not showing a trend\n",
    "# wavlength over time should be comparable\n",
    "mean = np.mean(AIRS_cds_binned, axis=(1,2), keepdims=True)\n",
    "std = np.std(AIRS_cds_binned, axis=(1,2), keepdims=True)\n",
    "min = np.min(AIRS_cds_binned, axis=(1,2), keepdims=True)\n",
    "max = np.max(AIRS_cds_binned, axis=(1,2), keepdims=True)\n",
    "\n",
    "zScoreAIRS = (AIRS_cds_binned - mean) / std # gets rid of overall trend -> frames get uncomparable between each other\n",
    "#zScoreAIRS = (AIRS_cds_binned - min) / (max - min) # frames get uncomparable between each other\n",
    "b = zScoreAIRS.sum(axis=(2,3))\n",
    "b = zScoreAIRS.sum(axis=(3))\n",
    "print(b.shape)\n",
    "plt.plot(b[0,:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing over entire intensity signal: makes stars comparable, but we don't really want that I guess, spectra are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
