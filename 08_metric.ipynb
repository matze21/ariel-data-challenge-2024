{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import scipy.stats\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        naive_mean: float,\n",
    "        naive_sigma: float,\n",
    "        sigma_true: float\n",
    "    ) -> float:\n",
    "    '''\n",
    "    This is a Gaussian Log Likelihood based metric. For a submission, which contains the predicted mean (x_hat) and variance (x_hat_std),\n",
    "    we calculate the Gaussian Log-likelihood (GLL) value to the provided ground truth (x). We treat each pair of x_hat,\n",
    "    x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian distributions, hence 283 values for each test spectrum,\n",
    "    the GLL value for one spectrum is the sum of all of them.\n",
    "\n",
    "    Inputs:\n",
    "        - solution: Ground Truth spectra (from test set)\n",
    "            - shape: (nsamples, n_wavelengths)\n",
    "        - submission: Predicted spectra and errors (from participants)\n",
    "            - shape: (nsamples, n_wavelengths*2)\n",
    "        naive_mean: (float) mean from the train set.\n",
    "        naive_sigma: (float) standard deviation from the train set.\n",
    "        sigma_true: (float) essentially sets the scale of the outputs.\n",
    "    '''\n",
    "\n",
    "    solution = solution.loc[solution.index != row_id_column_name]\n",
    "    submission = submission.loc[submission.index != row_id_column_name]\n",
    "\n",
    "    if submission.min().min() < 0:\n",
    "        raise ParticipantVisibleError('Negative values in the submission')\n",
    "    for col in submission.columns:\n",
    "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
    "\n",
    "    n_wavelengths = len(solution.columns)\n",
    "    if len(submission.columns) != n_wavelengths*2:\n",
    "        raise ParticipantVisibleError('Wrong number of columns in the submission')\n",
    "\n",
    "    y_pred = submission.iloc[:, :n_wavelengths].values\n",
    "    # Set a non-zero minimum sigma pred to prevent division by zero errors.\n",
    "    sigma_pred = np.clip(submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None)\n",
    "    y_true = solution.values\n",
    "\n",
    "    GLL_pred = (scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n",
    "    GLL_true = (scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n",
    "    GLL_mean = (scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n",
    "\n",
    "   # print(GLL_true, GLL_mean, GLL_pred[:,0])\n",
    "\n",
    "    GLL_pred = np.sum(GLL_pred)\n",
    "    GLL_true = np.sum(GLL_true)\n",
    "    GLL_mean = np.sum(GLL_mean)\n",
    "\n",
    "    submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n",
    "    return float(np.clip(submit_score, 0.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDf = pd.read_csv(\"train_labels.csv\")\n",
    "labelDf = labelDf.set_index('planet_id')\n",
    "\n",
    "mean = np.mean(labelDf.mean())\n",
    "std = np.std(labelDf.std())\n",
    "max = np.max(labelDf.max())\n",
    "min = np.min(labelDf.min())\n",
    "mean, std, max, min\n",
    "\n",
    "for col in labelDf.columns:\n",
    "    labelDf.loc[:,col] = (labelDf[col] - mean) / (std)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "files = glob.glob(os.path.join('train/', '*/*'))\n",
    "stars = []\n",
    "for file in files:\n",
    "    file_name = file.split('\\\\')[1]\n",
    "    stars.append(file_name)\n",
    "stars = np.unique(stars)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def split_star_list(file_list, test_ratio=0.2):\n",
    "    random.shuffle(file_list)\n",
    "    split_index = int(len(file_list) * (1 - test_ratio))\n",
    "    train_files = file_list[:split_index]\n",
    "    test_files = file_list[split_index:]\n",
    "    return train_files, test_files\n",
    "\n",
    "train_stars, test_stars = split_star_list(stars)\n",
    "\n",
    "def preprocess_data(features, labels):\n",
    "    # Perform any necessary preprocessing here\n",
    "    return features, labels\n",
    "\n",
    "def load_npz(star):\n",
    "    integer_value = tf.strings.to_number(star, out_type=tf.int64)\n",
    "    python_int = integer_value.numpy()\n",
    "    print(python_int)\n",
    "\n",
    "    file_path = 'train/'+str(python_int)+'/combined.npz'\n",
    "    try:\n",
    "        with np.load(file_path) as data:\n",
    "            features = data['a'][0,:,0:283,:]\n",
    "            labels = labelDf.loc[python_int].to_numpy()\n",
    "\n",
    "            features, labels = preprocess_data(features,labels)\n",
    "            return features, labels\n",
    "    except Exception as e:\n",
    "        print(\"Error loading file:\", e, python_int)\n",
    "    \n",
    "\n",
    "def create_dataset(star_list, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(star_list)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(star_list))\n",
    "    def load_and_process(x):\n",
    "        features, labels = tf.py_function(\n",
    "            func=load_npz,\n",
    "            inp=[x],\n",
    "            Tout=[tf.float64, tf.float32]\n",
    "        )\n",
    "        return features, labels\n",
    "\n",
    "    dataset = dataset.map(load_and_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(lambda x, y: (tf.ensure_shape(x,tf.TensorShape([5625, 283, 4])), tf.ensure_shape(y, tf.TensorShape([283]))))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = create_dataset(train_stars, batch_size, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_dataset))\n",
    "batch[0].dtype ,batch[1].dtype,batch[0].shape ,batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_zScoreTarget(y_trueZScore, y_pred):\n",
    "    # stdDev_zScorePred = 1/n * sqrt((y_zScore - y_zScoreMean)^2) = 1/n *sqrt(sum( (y-mean)/std - (y_mean-mean)/std )^2) = 1/n * sqrt(sum( (y-y_mean)/std )^2 )) = 1/std * 1/n * sqrt(sum(y-y_mean)^2) = stdDev / std\n",
    "    # stdDev_zScorePred = stdDev_pred / std\n",
    "    # y_pred contains 1. y_zScore 2. log(stdDev_zScore)\n",
    "\n",
    "    y_true = y_trueZScore * std + mean   # y_zScore = (y - mean) / std -> y = y_zScore *std + mean\n",
    "\n",
    "    y_predZScore = y_pred[:, :,0]\n",
    "    log_sigma = y_pred[:, :,1]  # Log of the standard deviation / we predict log(stdDev_zScore) = log(stdDev / std) = log(stdDev) - log(std) -> log(stdDev) = log(stdDev_zScore) + log(std)\n",
    "\n",
    "    y_pred0 = y_predZScore * std + mean\n",
    "    stdDev = tf.exp(log_sigma)*std  # Exponentiate to get variance + scale back from zscore \n",
    "    logStdDev = log_sigma + tf.math.log(std)\n",
    "\n",
    "    L_pred = -0.5*(tf.math.log(2*np.pi) + logStdDev + tf.square(y_true - y_pred0) / stdDev)\n",
    "    L_ref = -0.5*(tf.math.log(2*np.pi) +  tf.math.log(std*std) + tf.square(y_trueZScore))   # ( (y_true - mean)/std )^2 = y_trueZScore^2  (y_true = y_trueZScore * std + mean)\n",
    "    L_ideal = -0.5*(tf.math.log(2*np.pi) + tf.math.log(1e-10))\n",
    "\n",
    "    #print(L_ideal, L_ref[:,0], L_pred[:,0])\n",
    "\n",
    "    L = (tf.reduce_sum(L_pred) -tf.reduce_sum(L_ref)) / (tf.reduce_sum(L_ideal)*283*y_pred.shape[0] - tf.reduce_sum(L_ref))\n",
    "    \n",
    "    return L\n",
    "\n",
    "def log_loss_zScoreTarget(y_trueZScore, y_pred):\n",
    "    # stdDev_zScorePred = 1/n * sqrt((y_zScore - y_zScoreMean)^2) = 1/n *sqrt(sum( (y-mean)/std - (y_mean-mean)/std )^2) = 1/n * sqrt(sum( (y-y_mean)/std )^2 )) = 1/std * 1/n * sqrt(sum(y-y_mean)^2) = stdDev / std\n",
    "    # stdDev_zScorePred = stdDev_pred / std\n",
    "    # y_pred contains 1. y_zScore 2. log(stdDev_zScore)\n",
    "\n",
    "    y_true = y_trueZScore * std + mean   # y_zScore = (y - mean) / std -> y = y_zScore *std + mean\n",
    "\n",
    "    y_predZScore = y_pred[:, :,0]\n",
    "    log_sigma = y_pred[:, :,1]  # Log of the standard deviation / we predict log(stdDev_zScore) = log(stdDev / std) = log(stdDev) - log(std) -> log(stdDev) = log(stdDev_zScore) + log(std)\n",
    "\n",
    "    y_pred0 = y_predZScore * std + mean\n",
    "    stdDev = tf.exp(log_sigma)*std  # Exponentiate to get variance + scale back from zscore \n",
    "    logStdDev = log_sigma + tf.math.log(std)\n",
    "\n",
    "    L_pred = -0.5*(tf.math.log(2*np.pi) + logStdDev + tf.square(y_true - y_pred0) / stdDev)\n",
    "    L_ref = -0.5*(tf.math.log(2*np.pi) +  tf.math.log(std*std) + tf.square(y_trueZScore))   # ( (y_true - mean)/std )^2 = y_trueZScore^2  (y_true = y_trueZScore * std + mean)\n",
    "    L_ideal = -0.5*(tf.math.log(2*np.pi) + tf.math.log(1e-10))\n",
    "\n",
    "    L = (L_pred -L_ref) / (L_ideal - L_ref)\n",
    "    loss = -(L - 1)\n",
    "    #print(L)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"train_labels.csv\")\n",
    "labels = labels.set_index('planet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    factorSub = 10 #* 10**i\n",
    "    factorVar = (10**i)\n",
    "    print(1e-5 *(10**i))\n",
    "\n",
    "    mockedOut = np.log((np.ones((batch[1].shape[0], batch[1].shape[1], 2))/std * 1e-5 * factorVar)).astype(np.float32)\n",
    "    mockedOut[:,:,0] = batch[1]*factorSub\n",
    "    sub = labels*factorSub\n",
    "    sub = sub.merge((sub*0 + 1e-5* factorVar).astype(np.float64).rename(columns=lambda x: x+'std'), left_on=sub.index, right_on=sub.index, how='outer', suffixes=('','_std')).set_index('key_0')\n",
    "    sub = sub.loc[3267648621].to_frame().T\n",
    "    print(log_likelihood_zScoreTarget(batch[1], mockedOut), np.mean((batch[1]*std-mockedOut[:,:,0]*std)**2), score(labels,sub, '',mean,std,1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
